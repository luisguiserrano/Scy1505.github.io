<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"><![endif]-->
<!--[if IE 7]><html class="no-js lt-ie9 lt-ie8" <![endif]-->
<!--[if IE 8]><html class="no-js lt-ie9" <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>An intro to the most basic Machine Learning techniques through the Kaggle Example</title>

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="/assets/img/favicon.ico" />

    <!-- Come and get me RSS readers -->
    <link rel="alternate" type="application/rss+xml" title="Felipe's Place" href="http://scy1505.github.io/feed.xml" />
    
    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/style.css">
    <!--[if IE 8]><link rel="stylesheet" href="/assets/css/ie.css"><![endif]-->
    <link rel="canonical" href="http://scy1505.github.io/blog/Titanicmd/">

    <!-- Modernizr -->
    <script src="/assets/js/modernizr.custom.15390.js" type="text/javascript"></script>

     <!-- Google Analytics: change UA-XXXXX-X to be your site's ID. -->
<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-58263416-1', 'auto');
ga('send', 'pageview');

</script>
 
</head>


<body>

	 <div class="header">
     <div class="container">
         <h1 class="logo"><a href="/"> <font color="#5B0000">Felipe's Place</font></a></h1>
         <nav class="nav-collapse">
             <ul class="noList">
                 
                 <li class="element first  ">
                     <a href="/index.html">Home</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/about">About</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/contact">Contact</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/research">Research</a>
                 </li> 
                 
                 <li class="element   last">
                     <a href="/articles">Posts</a>
                 </li> 
                 
                 <!--<li>
                     <a href="/articles">Posts</a>
                 </li>-->
                 <li> <a href="https://github.com/scy1505" target="_blank">GitHub</a></li>
                 <!-- <li><a href="https://github.com/brianmaierjr/long-haul/archive/master.zip">Download Theme</a></li> -->
             </ul>
         </nav>
     </div>
 </div><!-- end .header -->


   	<div class="content">

   		
		 <div class="container">
        	 <div class="post">
  
  <h1 class="postTitle">An intro to the most basic Machine Learning techniques through the Kaggle Example</h1>
  <p class="meta">October 11, 2016 | <span class="time">57</span> Minute Read</p>
  
  
<p>The puppy scientific learning community is happy to have you on board with this course in the basic techniques of Machine Learning. So, Welcome!)</p>

<p>When learning data sciences, we are usually faced with the difficult choice of knowing where to learn. Luckily for us, the Internet has a huge amount of resources for all levels. Most people end up taking online classes like the ones in <a href="https://www.coursera.org/">Coursera</a>, <a href="https://www.edx.org/">edx</a>, or <a href="https://www.udacity.com/">Udacity</a>, and eventually walk their way to <a href="https://www.kaggle.com/">Kaggle</a>. Before getting into it, I want to mention the there are more advance resource out there and I will write about this in subsequent posts, but some of my favorites are <a href="http://cs231n.github.io/">CS231n: Convolutional Neural Networks for Visual Recognition.</a>  and <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">UCL Course on RL</a>.</p>

<p>When starting with Kaggle the first example you ought to go through is the Titanic Example, the goal is to use the techniques, that you already know, to predict the likeness of a passenger to survive. We do this next.</p>

<h2 id="the-titanic-data">The Titanic Data</h2>

<p>The RMS Titanic was a ship that sunk in 1912. The failure to have proper safety procedures and equipment led to a huge loss of life. Our goal is to find the features of a person that is more likely to have survived.</p>

<p>Before talking about the data, we need to import some standard packages:</p>

<ul>
  <li>numpy: Allows to deal with scientific computations.</li>
  <li>pandas: Helps dealing with datasets, series, and data related stuff.</li>
  <li>sklearn: Short for scientific kit for learning, contains several methods for (basic) machine learning. Quite useful!</li>
  <li>matplotlib: Package for plotting graphs and visualization of data.</li>
</ul>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">pandas</span> <span class="n">as</span> <span class="n">pd</span>
<span class="n">import</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">linear_model</span> <span class="n">as</span> <span class="n">lm</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">model_selection</span> <span class="n">import</span> <span class="no">GridSearchCV</span>
<span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="nf">pyplot</span> <span class="n">as</span> <span class="n">plt</span></code></pre></figure>

<p>If you are working in an Ipython Notebook, you want to add the line</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"> 

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span> </code></pre></figure>

<p>which allows for the matplotlib graphs to appear in line.</p>

<p>Our data is contained in two comma-separated values (cvs) files, and we can read the data via the panda package as follows.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s1">'train.csv'</span><span class="p">)</span>
<span class="nb">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s1">'test.csv'</span><span class="p">)</span></code></pre></figure>

<p>The data is saved in an object from the Pandas package call DataFrame.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">type</span><span class="p">(</span><span class="n">train</span><span class="p">)</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>pandas.core.frame.DataFrame
</code></pre>
</div>

<p>The data is divided into two parts; the training data, and the testing data. This is a common practice. You should always divide your data into a training and testing, and <em>only</em> use the testing data at the end.</p>

<p>Depending of the amount of data that is available you may choose between 10% to 30% for testing (We will see later that there is a further division that must be made to tune the parameters, this is done in the process of validation or cross-validation).</p>

<p>This division must be made with care, trying to preserve the homogeneity of the data in both parts, that is making sure that the training and testing are representative of the data as a whole. sklearn has several tools appropriated for this tasks, for example <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split">this</a>.</p>

<p>Let’s take a peek at the data. The method <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html">DataFrame.describe()</a> is design for this purpose.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>418.000000</td>
      <td>418.000000</td>
      <td>332.000000</td>
      <td>418.000000</td>
      <td>418.000000</td>
      <td>417.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1100.500000</td>
      <td>2.265550</td>
      <td>30.272590</td>
      <td>0.447368</td>
      <td>0.392344</td>
      <td>35.627188</td>
    </tr>
    <tr>
      <th>std</th>
      <td>120.810458</td>
      <td>0.841838</td>
      <td>14.181209</td>
      <td>0.896760</td>
      <td>0.981429</td>
      <td>55.907576</td>
    </tr>
    <tr>
      <th>min</th>
      <td>892.000000</td>
      <td>1.000000</td>
      <td>0.170000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>996.250000</td>
      <td>1.000000</td>
      <td>21.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.895800</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1100.500000</td>
      <td>3.000000</td>
      <td>27.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1204.750000</td>
      <td>3.000000</td>
      <td>39.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.500000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1309.000000</td>
      <td>3.000000</td>
      <td>76.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div>

<p>ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ
ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ
ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ
ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ
ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ</p>

<p>This gives the info for both DataFrames, note that there are 891 passengers in the train dataset and 418 in the test dataset. Furthermore, we get the basic info like the mean, standard deviation, etc.</p>

<p>But how does the data looks like? We can check the whole data by typing it. That is just typing train (Try it!). But this would look clutter, so instead we can get a sample by using the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html">method DataFrame.head()</a> or <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html">method DataFrame.tail()</a></p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<p>and for the test DataFrame</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">.</span><span class="nf">tail</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>415</th>
      <td>1307</td>
      <td>3</td>
      <td>Saether, Mr. Simon Sivertsen</td>
      <td>male</td>
      <td>38.5</td>
      <td>0</td>
      <td>0</td>
      <td>SOTON/O.Q. 3101262</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>416</th>
      <td>1308</td>
      <td>3</td>
      <td>Ware, Mr. Frederick</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>359309</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>417</th>
      <td>1309</td>
      <td>3</td>
      <td>Peter, Master. Michael J</td>
      <td>male</td>
      <td>NaN</td>
      <td>1</td>
      <td>1</td>
      <td>2668</td>
      <td>22.3583</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>

<p>The first thing we notice is that the feature “Survived’ appears in the train DataFrame, but it does not appear in the test DataSet, the reason is simple, this is what we want to predict. Before using machine learning techniques, we should understand how the data looks like and create ourselves some “common sense predictions”. To look at the data we use the matplotlib library.</p>

<h3 id="making-the-graphs-look-nice">Making the graphs look nice</h3>

<p>The matplotlib library is very versatile and will let us create beautiful graphs. Furthermore, the panda library uses the matplotlib and increases the type of graphs we can create. We first set some global parameters for the matplotlib, we can use the method <a href="http://matplotlib.org/users/customizing.html">matplotlib.rc()</a> to do this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plt</span><span class="p">.</span><span class="nf">rc</span><span class="p">(</span><span class="s1">'font'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s1">'fantasy'</span><span class="p">)</span></code></pre></figure>

<h3 id="a-first-look-at-the-data">A first look at the data</h3>

<p>From the data description above we note that there two numeric features: Age and Fare, and some categorical ones: Pclass, Sex, Embarked, etc. Let’s study the numerical ones first. We will create density distributions for the Age and Fare using the KDE plot option for <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html#pandas.DataFrame.plot">DataFrame.plot()</a>.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">));</span> <span class="c1"># We create our canvas.</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">7</span><span class="p">;</span> <span class="c1"># How transparent curves will be.</span>

<span class="c1"># Subdivides the canvas in one row and two columns and says we are plotting at the one with coordinates (0,0)</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span> 


<span class="c1"># Obtains the feature Age from the data set, then it plots this as a density function using the kde type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># Places the labes to the axis an graph</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'Age'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s2">"Density probability for Age"</span> <span class="p">)</span>

<span class="c1">#place the legend in the best possible position</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span>

<span class="c1"># Subdivides the canvas in one row and two columns and says we are plotting at the one with coordinates (0,1)</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Obtains the feature Fare from the data set, then it plots this as a density function using the kde type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># Places the labes to the axis an graph</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'Fare'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s2">"Density probability for Fare"</span> <span class="p">)</span>

<span class="c1">#place the legend in the best possible position</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_24_1.png" alt="" /></p>

<p>Next, we use bar graphs to show the Proportions of passengers in the categories Pclass, Sex, and Embarked. The idea is always the same, first we use DataFrame.Feature to create the data series associated to the feature, then <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html">Series.value_counts()</a> to create the data series associated to the relative frequencies of the unique values (note that this is achieved by the parameter normalize). Finally we use the plot method with the parameter kind set to ‘bar’ to get the bars graph.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">));</span> <span class="c1"># We create our canvas.</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">7</span><span class="p">;</span> <span class="c1"># How transparent curves will be.</span>

<span class="c1"># Subdivides the canvas in one row and three columns and says we are plotting at the one with coordinates (0,0)</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span> 

<span class="c1"># Obtains the feature Pclass from the data set, then plots this as bar graphs using the bar type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Pclass</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># Places the labes to the axis an graph</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'Passenger Classs'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Passenger ratio by Class'</span><span class="p">)</span>

<span class="c1">#place the legend in the best possible position</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">)</span>

<span class="c1"># Subdivides the canvas in one row and three columns and says we are plotting at the one with coordinates (0,0)</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 

<span class="c1"># Obtains the feature Sex from the data set, then plots this as bar graphs using the bar type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Sex</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Sex</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># Places the labels to the axis an graph</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'Sex'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Passenger ratio by Sex'</span><span class="p">)</span>

<span class="c1">#place the legend in the best possible position</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">)</span>

<span class="c1"># Subdivides the canvas in one row and three columns and says we are plotting at the one with coordinates (0,0)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> 

<span class="c1"># Obtains the feature Sex from the data set, then plots this as bar graphs using the bar type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Embarked</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Embarked</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># Places the labels to the axis an graph</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'Embarked'</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Passenger ratio by Embarked'</span><span class="p">)</span>

<span class="c1">#place the legend in the best possible position</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_26_0.png" alt="" /></p>

<p>A note about the feature Embarked. It means Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton).</p>

<p>Before comparing this different features with the likeness of survival, let’s see how many people survived.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0    549
1    342
Name: Survived, dtype: int64
</code></pre>
</div>

<p>That is, only 342 people survived in our training set, that is about 38%. It is reasonable to expect the same is true for our testing set, as long as the choice of the testing data was homogeneous with respect to the whole data set.</p>

<h3 id="are-younger-people-more-likely-to-survive">Are younger people more likely to survive?</h3>

<p>We can create a Data Series of the people who survived and look at their ages. We could do the same for people who didn’t survived.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">7</span>

<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Survived</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Not Survived'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Survived</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Survived'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s1">'Age'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s2">"What age group is more likely to survive?"</span> <span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_33_0.png" alt="" /></p>

<p>We can draw a couple of quick conclutions. First, there’s a small increase in the chances of survival for people between ~15  and 30 years old. Second, the chances of survival decreasse if you are less than 15. But the chances do not change if older than 30.</p>

<h3 id="are-men-or-women-more-likely-to-survive">Are men or women more likely to survive?</h3>

<p>We can proceed as before, but select the sex feature instead.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">7</span>

<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Survived</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="no">Sex</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Survived'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s1">'Age'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s2">"What sex is more likely to survive?"</span> <span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_37_0.png" alt="" /></p>

<p>That is about two thirds of the survivors are women and one third is men.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">7</span>

<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Survived</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="no">Sex</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Not Survived'</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s1">'Age'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s2">"What sex is more likely to no  survive?"</span> <span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_39_0.png" alt="" /></p>

<p>And less than one fifth of the ones that didn’t survived is female. We can conclude that there are better chances of surviving for female persons.  Let’s try to be more precise and divide the population into four subsets, FemSur, FemNoSur, MalSur, and MalNoSur. We create a new feature to keep this information, we will need an auxiliary function.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">AuxSexSur</span><span class="p">(</span><span class="no">C</span><span class="p">):</span>
    <span class="k">if</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Sex'</span><span class="p">]</span><span class="o">==</span><span class="s1">'female'</span> <span class="n">and</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Survived'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'Female Survivor'</span>
    <span class="n">elif</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Sex'</span><span class="p">]</span><span class="o">==</span><span class="s1">'female'</span> <span class="n">and</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Survived'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'Female No Survivor'</span>
    <span class="n">elif</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Sex'</span><span class="p">]</span><span class="o">==</span><span class="s1">'male'</span> <span class="n">and</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Survived'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'Male Survivor'</span>
    <span class="n">elif</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Sex'</span><span class="p">]</span><span class="o">==</span><span class="s1">'male'</span> <span class="n">and</span> <span class="no">C</span><span class="p">[</span><span class="s1">'Survived'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">'Male No Survivor'</span></code></pre></figure>

<p>And we build the new feature in a copy of our DataFrame train.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train2</span><span class="o">=</span><span class="n">train</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">train2</span><span class="p">[</span><span class="s1">'SexSur'</span><span class="p">]</span><span class="o">=</span><span class="n">train2</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="no">AuxSexSur</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p>We can now plot this data, we use a pie chart for this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">train2</span><span class="o">.</span><span class="no">SexSur</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'pie'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'Sex and Survival'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s2">"What sex is more likely to no  survive?"</span> <span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_45_0.png" alt="" /></p>

<p>This give us the outcome that if female the chances are about 2/3 of surviving meanwhile if male the chances are about 1/5.</p>

<h3 id="survival-with-respect-to-class">Survival with respect to class</h3>

<p>This is another likely factor into survival, so it is worth taking a look at it. Let’s plot what were the survival ratios in each of the classes.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">6</span>

<span class="n">ax0</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'First Class'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Second Class'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax0</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#78AB46'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Third Class'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax0</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_49_0.png" alt="" /></p>

<p>This clearly shows that people in upper classes had a highest chance of survival. But how do males and females survival compares in each class? We create DataFrames with only males and one with other males to find this out.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train_male</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Sex</span><span class="o">==</span><span class="s1">'male'</span><span class="p">]</span>
<span class="n">train_female</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Sex</span><span class="o">==</span><span class="s1">'female'</span><span class="p">]</span></code></pre></figure>

<p>We can now place all the information together.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">6</span>

<span class="n">ax1</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">train_female</span><span class="p">[</span><span class="n">train_female</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">);</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'First Class Female'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">train_female</span><span class="p">[</span><span class="n">train_female</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">);</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Second Class Female'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">train_female</span><span class="p">[</span><span class="n">train_female</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#78AB46'</span><span class="p">);</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Third Class Female'</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax3</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">train_male</span><span class="p">[</span><span class="n">train_male</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">);</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'First Class Male'</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax4</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">train_male</span><span class="p">[</span><span class="n">train_male</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">);</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Second Class Male'</span><span class="p">)</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax4</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">)</span>

<span class="n">ax5</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">train_male</span><span class="p">[</span><span class="n">train_male</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="no">Survived</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="nf">sort_index</span><span class="p">().</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">'#78AB46'</span><span class="p">);</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">'Third Class Male'</span><span class="p">)</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s1">'Percentage'</span><span class="p">)</span>
<span class="n">ax5</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s1">'1: Survived\n 0: Did not survive'</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span> <span class="c1"># This command allows the graph to loook nice, try to run it without it to find what happens.</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_53_0.png" alt="" /></p>

<p>This shows that first class females were by far the most likely group to survived. At heart this process we carried out is similar to a decision tree, we will come back to this later. We could keep doing this kinds of analysis and I encourage you to try your own. But, for us the next step is to clean the Data.</p>

<h2 id="cleaning-the-data">Cleaning the Data</h2>

<p>Data usually comes messy, luckily for us, the data is quite clean. The one thing that we can see in this data is that there is plenty of missing Data. We can see how much by using the DataFrame method <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html">DataFrame.isnull()</a>. This method returns a DataFrame object whose values are True if the data is missing or Null, and it returns False otherwise. We also use the method sum(), this counts the values associated with the feature.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
</code></pre>
</div>

<p>Note, that there are 177 ages missing, 687 missing Cabin features, and 2 for the feature embarked. We should also look at the testing data.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>PassengerId      0
Pclass           0
Name             0
Sex              0
Age             86
SibSp            0
Parch            0
Ticket           0
Fare             1
Cabin          327
Embarked         0
dtype: int64
</code></pre>
</div>

<p>For the testing set the missing info corresponds to age, Fare, and Cabin. We have two options for dealing with the missing data. We could get rid of this entries or we could try to approximate their values. The first option is not a good idea since our data set is already small, so our only option is approximate this data.</p>

<h3 id="port-of-embark">Port of Embark</h3>

<p>In <a href="https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic/notebook">here</a>  Doctor Megan Risdal notes that there’s a relation between the port of embarking, the Passanger class and the Fare. We use this to find what are the reasonable values for the missing port of embarking. Let’s first check whose info are we missing.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Embarked</span><span class="p">.</span><span class="nf">isnull</span><span class="p">()]</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>61</th>
      <td>62</td>
      <td>1</td>
      <td>1</td>
      <td>Icard, Miss. Amelie</td>
      <td>female</td>
      <td>38.0</td>
      <td>0</td>
      <td>0</td>
      <td>113572</td>
      <td>80.0</td>
      <td>B28</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>829</th>
      <td>830</td>
      <td>1</td>
      <td>1</td>
      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>
      <td>female</td>
      <td>62.0</td>
      <td>0</td>
      <td>0</td>
      <td>113572</td>
      <td>80.0</td>
      <td>B28</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now we can use a boxplot graph to find the most likely value.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s1">'Fare'</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">'Embarked'</span><span class="p">,</span><span class="s1">'Pclass'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s1">''</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span><span class="mi">1</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_65_0.png" alt="" /></p>

<p>That is for these passengers, the most likely scenario is that their port of embarking was ‘c’, which corresponds to Cherbourg. But is this correct? this seems reasonable just by reading from the Data, but it is usually better to look for “real” sources to complete the data, for example in <a href="https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html">Encyclopedia Titanica</a> we can find info about the passengers. For this case we have that Amelie Icard was Mrs. Stone maid and they boarded in Southampton, that is the port of embarking should be ‘S’.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Embarked</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span> <span class="s1">'Embarked'</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">);</span></code></pre></figure>

<h3 id="the-cabin">The Cabin</h3>

<p>For the missing cabins, our only option is to declare them unknown. As we want to do this in both dataframes, we just assign a label representing unknown for each DataFrame.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Cabin</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span> <span class="s1">'Cabin'</span><span class="p">,</span> <span class="s1">'Unk'</span><span class="p">)</span>
<span class="nb">test</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Cabin</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span><span class="s1">'Cabin'</span><span class="p">,</span><span class="s1">'Unk'</span><span class="p">);</span></code></pre></figure>

<h3 id="the-fare">The Fare</h3>

<p>We now deal with the missing Fare value in the test set. Clearly, the Fare should depend on the class and the embarking port. Let’s find what does the person with the missing person looks like.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">[</span><span class="nb">test</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">isnull</span><span class="p">()</span><span class="o">==</span><span class="no">True</span><span class="p">]</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>1044</td>
      <td>3</td>
      <td>Storey, Mr. Thomas</td>
      <td>male</td>
      <td>60.5</td>
      <td>0</td>
      <td>0</td>
      <td>3701</td>
      <td>NaN</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<p>We have several options for the Fare. The mean, the most common value, or the fifty percentile. Let’s find these values for passengers in third class embarked at Southampton (Embarked=’S’). First the most common value:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">train</span><span class="p">[(</span><span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Embarked</span><span class="o">==</span><span class="s1">'S'</span><span class="p">)]</span><span class="o">.</span><span class="no">Fare</span><span class="p">,</span><span class="nb">test</span><span class="p">[(</span><span class="nb">test</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">)</span><span class="o">&amp;</span> <span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Embarked</span><span class="o">==</span><span class="s1">'S'</span><span class="p">)]</span><span class="o">.</span><span class="no">Fare</span><span class="p">]).</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">head</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>8.0500    60
7.8958    43
7.7750    26
7.9250    23
7.8542    21
Name: Fare, dtype: int64
</code></pre>
</div>

<p>Second, the mean and percentiles:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">train</span><span class="p">[(</span><span class="n">train</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Embarked</span><span class="o">==</span><span class="s1">'S'</span><span class="p">)]</span><span class="o">.</span><span class="no">Fare</span><span class="p">,</span><span class="nb">test</span><span class="p">[(</span><span class="nb">test</span><span class="o">.</span><span class="no">Pclass</span><span class="o">==</span><span class="mi">3</span><span class="p">)</span><span class="o">&amp;</span> <span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Embarked</span><span class="o">==</span><span class="s1">'S'</span><span class="p">)]</span><span class="o">.</span><span class="no">Fare</span><span class="p">]).</span><span class="nf">describe</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>count    494.000000
mean      14.435422
std       13.118281
min        0.000000
25%        7.854200
50%        8.050000
75%       15.900000
max       69.550000
Name: Fare, dtype: float64
</code></pre>
</div>

<p>From this data, a sensible choice would be to assign 8.05. But again a little research, see <a href="https://www.encyclopedia-titanica.org/titanic-victim/thomas-storey.html">here</a> shows that the passenger’s ticket was bought at the same time as those of  Andrew Shannon [Lionel Leonard], August Johnson, William Henry Törnquist, Alfred Carver and William Cahoone Johnson. Let’s find the fares for these passengers.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Name</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="s1">'Leonard'</span> <span class="k">in</span> <span class="n">x</span><span class="p">)]</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>0</td>
      <td>3</td>
      <td>Palsson, Master. Gosta Leonard</td>
      <td>male</td>
      <td>2.0</td>
      <td>3</td>
      <td>1</td>
      <td>349909</td>
      <td>21.0750</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>121</th>
      <td>122</td>
      <td>0</td>
      <td>3</td>
      <td>Moore, Mr. Leonard Charles</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>A4. 54510</td>
      <td>8.0500</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>179</th>
      <td>180</td>
      <td>0</td>
      <td>3</td>
      <td>Leonard, Mr. Lionel</td>
      <td>male</td>
      <td>36.0</td>
      <td>0</td>
      <td>0</td>
      <td>LINE</td>
      <td>0.0000</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>248</th>
      <td>249</td>
      <td>1</td>
      <td>1</td>
      <td>Beckwith, Mr. Richard Leonard</td>
      <td>male</td>
      <td>37.0</td>
      <td>1</td>
      <td>1</td>
      <td>11751</td>
      <td>52.5542</td>
      <td>D35</td>
      <td>S</td>
    </tr>
    <tr>
      <th>386</th>
      <td>387</td>
      <td>0</td>
      <td>3</td>
      <td>Goodwin, Master. Sidney Leonard</td>
      <td>male</td>
      <td>1.0</td>
      <td>5</td>
      <td>2</td>
      <td>CA 2144</td>
      <td>46.9000</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>626</th>
      <td>627</td>
      <td>0</td>
      <td>2</td>
      <td>Kirkland, Rev. Charles Leonard</td>
      <td>male</td>
      <td>57.0</td>
      <td>0</td>
      <td>0</td>
      <td>219533</td>
      <td>12.3500</td>
      <td>Unk</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>655</th>
      <td>656</td>
      <td>0</td>
      <td>2</td>
      <td>Hickman, Mr. Leonard Mark</td>
      <td>male</td>
      <td>24.0</td>
      <td>2</td>
      <td>0</td>
      <td>S.O.C. 14879</td>
      <td>73.5000</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>758</th>
      <td>759</td>
      <td>0</td>
      <td>3</td>
      <td>Theobald, Mr. Thomas Leonard</td>
      <td>male</td>
      <td>34.0</td>
      <td>0</td>
      <td>0</td>
      <td>363294</td>
      <td>8.0500</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>871</th>
      <td>872</td>
      <td>1</td>
      <td>1</td>
      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>
      <td>female</td>
      <td>47.0</td>
      <td>1</td>
      <td>1</td>
      <td>11751</td>
      <td>52.5542</td>
      <td>D35</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Name</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="s1">'Johnson'</span> <span class="k">in</span> <span class="n">x</span><span class="p">)]</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>1</td>
      <td>3</td>
      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>
      <td>female</td>
      <td>27.0</td>
      <td>0</td>
      <td>2</td>
      <td>347742</td>
      <td>11.1333</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>172</th>
      <td>173</td>
      <td>1</td>
      <td>3</td>
      <td>Johnson, Miss. Eleanor Ileen</td>
      <td>female</td>
      <td>1.0</td>
      <td>1</td>
      <td>1</td>
      <td>347742</td>
      <td>11.1333</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>302</th>
      <td>303</td>
      <td>0</td>
      <td>3</td>
      <td>Johnson, Mr. William Cahoone Jr</td>
      <td>male</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>LINE</td>
      <td>0.0000</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>597</th>
      <td>598</td>
      <td>0</td>
      <td>3</td>
      <td>Johnson, Mr. Alfred</td>
      <td>male</td>
      <td>49.0</td>
      <td>0</td>
      <td>0</td>
      <td>LINE</td>
      <td>0.0000</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>719</th>
      <td>720</td>
      <td>0</td>
      <td>3</td>
      <td>Johnson, Mr. Malkolm Joackim</td>
      <td>male</td>
      <td>33.0</td>
      <td>0</td>
      <td>0</td>
      <td>347062</td>
      <td>7.7750</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
    <tr>
      <th>869</th>
      <td>870</td>
      <td>1</td>
      <td>3</td>
      <td>Johnson, Master. Harold Theodor</td>
      <td>male</td>
      <td>4.0</td>
      <td>1</td>
      <td>1</td>
      <td>347742</td>
      <td>11.1333</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="no">Name</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="s1">'Tornquist'</span> <span class="k">in</span> <span class="n">x</span><span class="p">)]</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>271</th>
      <td>272</td>
      <td>1</td>
      <td>3</td>
      <td>Tornquist, Mr. William Henry</td>
      <td>male</td>
      <td>25.0</td>
      <td>0</td>
      <td>0</td>
      <td>LINE</td>
      <td>0.0</td>
      <td>Unk</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<p>So, none of them paid for the ticket. The reason is because they were forced into the Titanic as another ship couldn’t make the trip because of scheduling problems. So according to this the right value for fare should be 0.0.</p>

<p>But note that there’s an inconsistency. All of his shipmates have LINE under the ticket feature, but Storey, Mr. Thomas does not. I wonder why this happened? Lacking more information I think the value for Storey, Mr. Thomas should be the most common on, that is 8.05</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span><span class="s1">'Fare'</span><span class="p">,</span><span class="mi">8</span><span class="o">.</span><span class="mo">05</span><span class="p">);</span></code></pre></figure>

<h3 id="the-age-feature">The Age Feature</h3>

<p>We now turn to the missing Age values. A first option would be to replace them all by them for something similar to the case of Fare, but this is case dependent so, probably, not a reasonable thing to do; the amount of ages missing is more than 1/5. Instead, we will create a learning tool that predicts the age. We need to introduce some features first, that will help us later on as well.</p>

<h2 id="some-new-features">Some new Features</h2>

<p>What other information can we extract from the features we already have? Let’s look at them again. We can use the method <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html">DataFrame.sample()</a> for this purpose.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></code></pre></figure>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>691</th>
      <td>692</td>
      <td>1</td>
      <td>3</td>
      <td>Karun, Miss. Manca</td>
      <td>female</td>
      <td>4.0</td>
      <td>0</td>
      <td>1</td>
      <td>349256</td>
      <td>13.4167</td>
      <td>Unk</td>
      <td>C</td>
    </tr>
    <tr>
      <th>195</th>
      <td>196</td>
      <td>1</td>
      <td>1</td>
      <td>Lurette, Miss. Elise</td>
      <td>female</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17569</td>
      <td>146.5208</td>
      <td>B80</td>
      <td>C</td>
    </tr>
    <tr>
      <th>809</th>
      <td>810</td>
      <td>1</td>
      <td>1</td>
      <td>Chambers, Mrs. Norman Campbell (Bertha Griggs)</td>
      <td>female</td>
      <td>33.0</td>
      <td>1</td>
      <td>0</td>
      <td>113806</td>
      <td>53.1000</td>
      <td>E8</td>
      <td>S</td>
    </tr>
    <tr>
      <th>224</th>
      <td>225</td>
      <td>1</td>
      <td>1</td>
      <td>Hoyt, Mr. Frederick Maxfield</td>
      <td>male</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>19943</td>
      <td>90.0000</td>
      <td>C93</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>

<p>Note that the Name Feature contains more information. The title: like Mr, Mrs, Dr, etc., and the surname that gives us info about groups of people traveling together (families).  The SibSp and Parch tell how large the family group is. The Cabin may be related to economical status. So let’s create features that encode this.</p>

<h3 id="features-from-text">Features from text</h3>

<p>There are many tools to mine info out of text, most of them use regular expression. We load the python package to handle regular expressions.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">import</span> <span class="n">re</span></code></pre></figure>

<p>We want to break each of the names into parts and then categorize those. Note that the data before the comma is the last name and there’s usually a tittle associated with the person mr, mrs, etc. We create a function to extract this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">extractInfo</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="n">pat</span><span class="o">=</span><span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="s1">'(?P&lt;surname&gt;.+?), (?P&lt;title&gt;.*?)\.'</span><span class="p">)</span>
    <span class="no">A</span><span class="o">=</span><span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">pat</span><span class="p">,</span><span class="n">word</span><span class="p">)</span>
    <span class="no">B</span><span class="o">=</span><span class="p">[</span><span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'surname'</span><span class="p">),</span><span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)]</span>
    <span class="k">if</span> <span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span> <span class="k">in</span> <span class="p">[</span><span class="s1">'Mme'</span><span class="p">]:</span>
        <span class="no">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s1">'Mrs'</span>
    <span class="n">elif</span>  <span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span> <span class="k">in</span> <span class="p">[</span><span class="s1">'Ms'</span><span class="p">,</span><span class="s1">'Mlle'</span><span class="p">]:</span>
        <span class="no">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s1">'Miss'</span>
    <span class="n">elif</span>  <span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span> <span class="k">in</span> <span class="p">[</span><span class="s1">'Don'</span><span class="p">,</span> <span class="s1">'Jonkheer'</span><span class="p">,</span><span class="s1">'Master'</span><span class="p">]:</span>
        <span class="no">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s1">'Sir'</span>
    <span class="n">elif</span> <span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span> <span class="k">in</span> <span class="p">[</span><span class="s1">'Dona'</span><span class="p">,</span> <span class="s1">'Lady'</span><span class="p">,</span> <span class="s1">'the Countess'</span><span class="p">]:</span>
        <span class="no">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s1">'Lady'</span>
    <span class="n">elif</span> <span class="no">A</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span> <span class="k">in</span> <span class="p">[</span><span class="s1">'Capt'</span><span class="p">,</span> <span class="s1">'Col'</span><span class="p">,</span> <span class="s1">'Major'</span><span class="p">,</span> <span class="s1">'Dr'</span><span class="p">,</span> <span class="s1">'Officer'</span><span class="p">,</span> <span class="s1">'Rev'</span><span class="p">]:</span>
        <span class="no">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="s1">'Officer'</span>

    <span class="k">return</span> <span class="no">B</span></code></pre></figure>

<p>The only nontrivial part here is how regular expressions work. Each set of parenthesis corresponds to a group, whose corresponding name is written after ?P in triangular brackets. “.+” means find any character except end of the line  and repeat at least once, “.*” means repeat zero or more times, and the ? after them means that is ungreedy (lazy). more detailed explanations <a href="https://docs.python.org/3/howto/regex.html">here</a> and <a href="http://www.regular-expressions.info/repeat.html">here</a>. We input these new features next.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1">#New features for train</span>
<span class="n">temp</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="no">Name</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">extractInfo</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">'Surname'</span><span class="p">]</span><span class="o">=</span><span class="n">temp</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s1">'Title'</span><span class="p">]</span><span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>   

<span class="c1">#New features for test</span>
<span class="n">temp</span><span class="o">=</span><span class="nb">test</span><span class="o">.</span><span class="no">Name</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">extractInfo</span><span class="p">)</span>
<span class="nb">test</span><span class="p">[</span><span class="s1">'Surname'</span><span class="p">]</span><span class="o">=</span><span class="n">temp</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">test</span><span class="p">[</span><span class="s1">'Title'</span><span class="p">]</span><span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nb">lambda</span> <span class="ss">x: </span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>   </code></pre></figure>

<p>Let’s check what we got:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="o">.</span><span class="no">Title</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span><span class="o">+</span><span class="nb">test</span><span class="o">.</span><span class="no">Title</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>Mr         757
Miss       264
Mrs        198
Sir         64
Officer     23
Lady         3
Name: Title, dtype: int64
</code></pre>
</div>

<h3 id="groups">Groups</h3>

<p>The size of a family is relevant for the survival, we can think it this way families tend to survive or die together. So, we would like to keep track of this. We create two features to keep track of the size:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>-group_count: the number of people in the group.  
-group_size:  'S' if group_count&lt;2, 'M' is 2&lt;= group_count&lt;=4, 'L' if group_count&gt;4. 
</code></pre>
</div>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">[</span><span class="s1">'group_count'</span><span class="p">]</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="no">Parch</span> <span class="o">+</span> <span class="n">train</span><span class="o">.</span><span class="no">SibSp</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">test</span><span class="p">[</span><span class="s1">'group_count'</span><span class="p">]</span><span class="o">=</span><span class="nb">test</span><span class="o">.</span><span class="no">Parch</span> <span class="o">+</span> <span class="nb">test</span><span class="o">.</span><span class="no">SibSp</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">train</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'M'</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">)</span>
<span class="n">train</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&gt;</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'L'</span><span class="p">)</span>

<span class="nb">test</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="nb">test</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'M'</span><span class="p">)</span>
<span class="nb">test</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="nb">test</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'S'</span><span class="p">)</span>
<span class="nb">test</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="nb">test</span><span class="p">.</span><span class="nf">group_count</span><span class="o">&gt;</span><span class="mi">4</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">,</span> <span class="s1">'L'</span><span class="p">);</span></code></pre></figure>

<h3 id="normalizing-the-fare-data">Normalizing the Fare Data</h3>

<p>Our next and final step before creating the classifier is to normalized fare, by first translating the mean and dividing by the standard deviation. This finishes our <a href="http://machinelearningmastery.com/how-to-prepare-data-for-machine-learning/">preprocesing</a>. We import the Standard Scaler from Sklearn.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">preprocessing</span> <span class="n">import</span> <span class="no">StandardScaler</span> 
<span class="n">scaler</span><span class="o">=</span><span class="no">StandardScaler</span><span class="p">()</span></code></pre></figure>

<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform">StandardScaler</a> has several methods:</p>

<ul>
  <li>fit(): computes the mean and standard deviation for later used.</li>
  <li>transform(): transform the data using the mean and standard deviation already trained.</li>
  <li>fit_transform(): does the previous two.</li>
</ul>

<p>in versions &lt;= 0.17 sklearn could take 1-dim’l arrays and use this to train and compute. Since then this has been deprecated. In our case, the data comes as a one-dimensional array, so we need to reshape it.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fares</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="no">Fare</span><span class="p">,</span><span class="nb">test</span><span class="o">.</span><span class="no">Fare</span><span class="p">])</span> <span class="c1"># concatenate the train.Fare Data Series and the test.Fare Data Series</span>

<span class="n">scaler</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">fares</span><span class="p">.</span><span class="nf">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># Find the mean and std to be used later</span>

<span class="c1">#Normalizes the data for train and adds the feature NorFare.</span>
<span class="n">train</span><span class="p">[</span><span class="s1">'NorFare'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">Series</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">train</span><span class="p">.</span><span class="nf">index</span><span class="p">)</span> 

<span class="c1">#Normalizes the data for test and adds the feature NorFare.</span>
<span class="nb">test</span><span class="p">[</span><span class="s1">'NorFare'</span><span class="p">]</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="no">Series</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Fare</span><span class="p">.</span><span class="nf">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="nb">test</span><span class="p">.</span><span class="nf">index</span><span class="p">)</span> </code></pre></figure>

<p>We now turn to the prediction of the Age Feature.</p>

<h3 id="predicting-age">Predicting Age</h3>

<p>In order to predict the Age, we follow the following steps:</p>

<ul>
  <li>Combine the data from train and test.</li>
  <li>Choose the relevant features to predict Age.</li>
  <li>Separate the known Ages from the unknown ones.</li>
  <li>Divide the known ones into the ones for training and the ones for testing.p</li>
  <li>Create the classifier.</li>
  <li>Test the classifier accuracy.</li>
  <li>Predict the unknown ages.</li>
</ul>

<h4 id="combining-choosing-the-relevant-features-and-separating">Combining, choosing the relevant features, and separating</h4>

<p>We use <a href="http://pandas.pydata.org/pandas-docs/stable/merging.html">pd.concat()</a> to put the data together.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">allData</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span><span class="nb">test</span><span class="p">])</span></code></pre></figure>

<p>We <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html">drop</a> the irrelevant features.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">allData</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'PassengerId'</span><span class="p">,</span> <span class="s1">'Name'</span><span class="p">,</span> <span class="s1">'Cabin'</span><span class="p">,</span><span class="s1">'Survived'</span><span class="p">,</span> <span class="s1">'Ticket'</span><span class="p">,</span> <span class="s1">'Fare'</span><span class="p">,</span><span class="s1">'Surname'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span></code></pre></figure>

<p>Next we make the categorical variables into indicator variables. We use the method <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html">get_dummies</a> for this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">allData</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="n">allData</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Embarked'</span><span class="p">,</span> <span class="s1">'Sex'</span><span class="p">,</span> <span class="s1">'Title'</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">])</span></code></pre></figure>

<p>We obtain the known ages</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">knownAges</span><span class="o">=</span><span class="n">allData</span><span class="p">[</span><span class="o">~</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">isnull</span><span class="p">()]</span></code></pre></figure>

<p>We separate the features use for the model from the target feature.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X</span><span class="o">=</span><span class="n">knownAges</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s1">'Age'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="no">Y</span><span class="o">=</span><span class="n">knownAges</span><span class="o">.</span><span class="no">Age</span></code></pre></figure>

<p>We split the data into training and testing.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">model_selection</span> <span class="n">import</span> <span class="n">train_test_split</span>
<span class="no">X_train</span><span class="p">,</span> <span class="no">X_test</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="no">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="no">X</span><span class="p">,</span><span class="no">Y</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span></code></pre></figure>

<p>We aim to use <a href="https://en.wikipedia.org/wiki/Gradient_boosting">gradient boosting</a>. In this fork we use adaboost instead of xgboost. Keep in mind that <a href="http://xgboost.readthedocs.io/en/latest/">xgboost</a> has better performance; go to the master branch for the use of xgboost.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">ensemble</span> <span class="n">import</span> <span class="no">AdaBoostRegressor</span>
<span class="n">model</span><span class="o">=</span><span class="no">AdaBoostRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span></code></pre></figure>

<p>In order to make sure we get the best classifier we use GridSearchCV to find the parameters that will give us the best fit.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">parameters</span><span class="o">=</span><span class="p">{</span><span class="s1">'n_estimators'</span><span class="ss">:range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="s1">'learning_rate'</span><span class="p">:[</span><span class="n">x</span><span class="o">*</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span><span class="o">+</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">19</span><span class="p">)]}</span>
<span class="n">ageClas</span><span class="o">=</span><span class="no">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">parameters</span><span class="p">)</span>
<span class="n">ageClas</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span><span class="no">Y_train</span> <span class="p">);</span></code></pre></figure>

<p>We are ready to test how well we did.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">ageClas</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="no">X_test</span><span class="p">,</span><span class="no">Y_test</span><span class="p">)</span></code></pre></figure>

<hr />
<p>0.42300319376063289</p>

<hr />

<p>This is not pretty good, but it would be difficult to achieve better accuracy with such a small data set and not much relevant data to age. Let’s see what features were more important. We first find what was the best classifier that the GridSSearch found.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">ageClas</span><span class="p">.</span><span class="nf">best_params_</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="err">'learning_rate':</span><span class="w"> </span><span class="err">0.1,</span><span class="w"> </span><span class="err">'n_estimators':</span><span class="w"> </span><span class="err">4</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>Then, we create the classifier associated with those parameters and see what were the important features.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">model2</span><span class="o">=</span><span class="no">AdaBoostRegressor</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">model2</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span><span class="no">Y_train</span><span class="p">)</span>
<span class="n">model2</span><span class="p">.</span><span class="nf">feature_importances_</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>array([  7.03742379e-03,   9.16024507e-02,   2.34270827e-01,
         0.00000000e+00,   1.07496543e-02,   7.87789897e-06,
         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
         0.00000000e+00,   0.00000000e+00,   2.97504208e-01,
         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
         3.58827559e-01,   0.00000000e+00,   0.00000000e+00,
         0.00000000e+00])
</code></pre>
</div>

<p>this gives the third and twelve features as the most important ones. This correspond to Siblings, the fact if the person have a title of Mr. and if it has a title of Sir. Let’s use this regressors to give the unknown values to Age.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">pred</span> <span class="o">=</span> <span class="n">ageClas</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">allData</span><span class="p">[</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">isnull</span><span class="p">()].</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'Age'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">allData</span><span class="p">.</span><span class="nf">set_value</span><span class="p">(</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">isnull</span><span class="p">(),</span> <span class="s1">'Age'</span><span class="p">,</span> <span class="n">pred</span><span class="p">);</span></code></pre></figure>

<p>We can now compare the density plot for Age with the one we had before.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">));</span> <span class="c1"># We create our canvas.</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">7</span><span class="p">;</span> <span class="c1"># How transparent curves will be.</span>

<span class="c1"># Subdivides the canvas in one row and two columns and says we are plotting at the one with coordinates (0,0)</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span> 


<span class="c1"># Obtains the feature Age from the data set, then it plots this as a density function using the kde type for DataFrame.plot()</span>
<span class="n">train</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'#FA2379'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
<span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'kde'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'All Data after prediction of Ages'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_136_0.png" alt="" /></p>

<p>Finally, let’s put this results back in the train and test dataFrames.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="o">.</span><span class="no">Age</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">[:</span><span class="mi">891</span><span class="p">]</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Age</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">[</span><span class="mi">891</span><span class="p">:]</span></code></pre></figure>

<p>We can now move into creating our classifiers for predicting survival.</p>

<h2 id="predicting-survival">Predicting Survival</h2>

<p>Before predicting survival we need to make the data ready to train the classifiers.</p>

<h3 id="normalizing">Normalizing</h3>

<p>We have already normalized fare. But we still need to normalize Age and group_count.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">allData</span><span class="p">[</span><span class="s1">'NorAge'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">Series</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">allData</span><span class="o">.</span><span class="no">Age</span><span class="p">.</span><span class="nf">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">0</span><span class="o">.</span><span class="mi">0</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">allData</span><span class="p">.</span><span class="nf">index</span><span class="p">)</span>
<span class="n">allData</span><span class="p">[</span><span class="s1">'NorGroup_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">Series</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">allData</span><span class="p">.</span><span class="nf">group_count</span><span class="p">.</span><span class="nf">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">0</span><span class="o">.</span><span class="mi">0</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">allData</span><span class="p">.</span><span class="nf">index</span><span class="p">)</span>

<span class="n">train</span><span class="p">[</span><span class="s1">'NorAge'</span><span class="p">]</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">NorAge</span><span class="p">[:</span><span class="mi">891</span><span class="p">]</span>
<span class="n">train</span><span class="p">[</span><span class="s1">'NorGroup_count'</span><span class="p">]</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">NorGroup_count</span><span class="p">[:</span><span class="mi">891</span><span class="p">]</span>

<span class="nb">test</span><span class="p">[</span><span class="s1">'NorAge'</span><span class="p">]</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">NorAge</span><span class="p">[</span><span class="mi">891</span><span class="p">:]</span>
<span class="nb">test</span><span class="p">[</span><span class="s1">'NorGroup_count'</span><span class="p">]</span><span class="o">=</span><span class="n">allData</span><span class="o">.</span><span class="no">NorGroup_count</span><span class="p">[</span><span class="mi">891</span><span class="p">:]</span></code></pre></figure>

<h3 id="gender-as-values">Gender as values</h3>

<p>We encode female gender as 1 and male as 0.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="o">.</span><span class="no">Sex</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="no">Sex</span><span class="o">==</span><span class="s1">'Female'</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">test</span><span class="o">.</span><span class="no">Sex</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="nb">test</span><span class="o">.</span><span class="no">Sex</span><span class="o">==</span><span class="s1">'Female'</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span></code></pre></figure>

<p>We get rid of the features we need no more and the Surname feature since we won’t use it.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'PassengerId'</span><span class="p">,</span> <span class="s1">'Surname'</span><span class="p">,</span><span class="s1">'Name'</span><span class="p">,</span> <span class="s1">'Cabin'</span><span class="p">,</span> <span class="s1">'Ticket'</span><span class="p">,</span> <span class="s1">'Age'</span><span class="p">,</span> <span class="s1">'Fare'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="nb">test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">'Name'</span><span class="p">,</span> <span class="s1">'Cabin'</span><span class="p">,</span> <span class="s1">'Surname'</span><span class="p">,</span><span class="s1">'Ticket'</span><span class="p">,</span> <span class="s1">'Age'</span><span class="p">,</span> <span class="s1">'Fare'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span></code></pre></figure>

<h3 id="indicatordummy-features">Indicator/Dummy Features</h3>

<p>As we did above with Age, we need to make the features numeric, we can do this with Dummy Features. (Note that as we are keeping the surname feature the dimensionality should increase considerably)</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">train</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Embarked'</span><span class="p">,</span> <span class="s1">'Title'</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">])</span>
<span class="nb">test</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">get_dummies</span><span class="p">(</span><span class="nb">test</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'Embarked'</span><span class="p">,</span> <span class="s1">'Title'</span><span class="p">,</span> <span class="s1">'group_size'</span><span class="p">])</span></code></pre></figure>

<h3 id="some-tools-for-graphing">Some tools for graphing</h3>

<p>In order to see how the classifiers behave we will use some extra tools. First the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.learning_curve.learning_curve.html#sklearn.learning_curve">learning_curve</a> method. It Determines cross-validated training and test scores for different training set sizes.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">model_selection</span> <span class="n">import</span> <span class="n">learning_curve</span></code></pre></figure>

<p>Then we follow the <a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html">sklearn docs</a> to create a function that graphs the learning cure for a given classifier.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">plot_learning_curve</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="no">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="no">None</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)):</span>
    <span class="s2">"""
    Generate a simple plot of the test and training learning curve.

    Parameters
    ----------
    estimator : object type that implements the "</span><span class="n">fit</span><span class="s2">" and "</span><span class="n">predict</span><span class="s2">" methods
        An object of that type which is cloned for each validation.

    title : string
        Title for the chart.

    X : array-like, shape (n_samples, n_features)
        Training vector, where n_samples is the number of samples and
        n_features is the number of features.

    y : array-like, shape (n_samples) or (n_samples, n_features), optional
        Target relative to X for classification or regression;
        None for unsupervised learning.

    ylim : tuple, shape (ymin, ymax), optional
        Defines minimum and maximum yvalues plotted.

    cv : int, cross-validation generator or an iterable, optional
        Determines the cross-validation splitting strategy.
        Possible inputs for cv are:
          - None, to use the default 3-fold cross-validation,
          - integer, to specify the number of folds.
          - An object to be used as a cross-validation generator.
          - An iterable yielding train/test splits.

        For integer/None inputs, if ``y`` is binary or multiclass,
        :class:`StratifiedKFold` used. If the estimator is not a classifier
        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.

        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various
        cross-validators that can be used here.

    n_jobs : integer, optional
        Number of jobs to run in parallel (default 1).
    """</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylim</span> <span class="n">is</span> <span class="n">not</span> <span class="no">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">*</span><span class="n">ylim</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s2">"Training examples"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="s2">"Score"</span><span class="p">)</span>
    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">()</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s2">"r"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"g"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"r"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">"Training score"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"g"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">"Cross-validation score"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">"best"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">plt</span></code></pre></figure>

<h3 id="choosing-the-right-parameters">Choosing the right parameters</h3>

<p>The choice of a classifier usually depends on a choice of parameters. There are automatic ways of doing this, we use before above when coming up with a classifier for Age, that is GridSearchCV. The next function takes a classifier, a range of values for the parameters, some training data, a scoring method and returns the classifier associated with the best parameters.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">bestClass</span><span class="p">(</span><span class="n">clas</span><span class="p">,</span><span class="n">parameters</span><span class="p">,</span><span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">):</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="no">GridSearchCV</span><span class="p">(</span><span class="n">clas</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">grid</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span><span class="no">Y_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grid</span><span class="p">.</span><span class="nf">best_estimator_</span></code></pre></figure>

<p>Note the scoring function, we talk about this next.</p>

<h3 id="measuring-accuracy">Measuring accuracy.</h3>

<p>Next, we import a method to measure accuracy, we import <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score">accuracy_score</a> which finds the percentage of correct predictions.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">metrics</span> <span class="n">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">make_scorer</span></code></pre></figure>

<p>Even though this is a function that computes accuracy, we need to wrapp it to make it a scoring function. That is what <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer">make_scorer</a> does.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">scoring</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="no">True</span><span class="p">)</span></code></pre></figure>

<h3 id="splitting-data">Splitting Data</h3>

<p>We split the data into training and test as we did with Age above.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s1">'Survived'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="no">Y</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="no">Survived</span>
<span class="no">X_train</span><span class="p">,</span> <span class="no">X_test</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="no">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span></code></pre></figure>

<p>We will create different classifiers and see how they perform.</p>

<h2 id="k-nearest-neighbors-knn">K-nearest Neighbors (KNN)</h2>

<p>The <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">K-nearest neighbors</a> is a classifier that basically outputs the average of the values of its k nearest neighbors.  You can find more info about it [here].</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">neighbors</span> <span class="n">import</span> <span class="no">KNeighborsClassifier</span>
<span class="no">KNN</span> <span class="o">=</span> <span class="no">KNeighborsClassifier</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'uniform'</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'n_neighbors'</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="s1">'p'</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]}</span>
<span class="n">clf_knn</span> <span class="o">=</span> <span class="n">bestClass</span><span class="p">(</span><span class="no">KNN</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span></code></pre></figure>

<p>We can see how well we did.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_knn</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.80717488789237668
</code></pre>
</div>

<p>And look at a graph on how the accuracy improves against the training data size.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_knn</span><span class="p">,</span> <span class="s1">'KNN'</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_177_0.png" alt="" /></p>

<h2 id="random-forest">Random Forest</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> classifier is an ensemble kind of classifier, made out of decision trees. It usually helps with the overclassifying problem that decision trees tend to have. More info [here].</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">ensemble</span> <span class="n">import</span> <span class="no">RandomForestClassifier</span>
<span class="n">rfc</span> <span class="o">=</span> <span class="no">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'entropy'</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'n_estimators'</span><span class="p">:[</span><span class="mi">300</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span> <span class="s1">'min_samples_leaf'</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]}</span>
<span class="n">clf_rfc1</span> <span class="o">=</span> <span class="n">bestClass</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span></code></pre></figure>

<p>We can see how well Random Forest does.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_rfc1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.8340807174887892
</code></pre>
</div>

<p>The learning curve graph is</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_rfc1</span><span class="p">,</span> <span class="s1">'Random Forest'</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_184_0.png" alt="" /></p>

<p>This isn’t pretty good, can we improve this? Let’s check how many features contributed more than 0.1%.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">clf_rfc1</span><span class="p">.</span><span class="nf">feature_importances_</span><span class="p">[</span><span class="n">clf_rfc1</span><span class="p">.</span><span class="nf">feature_importances_</span><span class="o">&gt;</span><span class="mi">0</span><span class="o">.</span><span class="mo">001</span><span class="p">]</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>array([ 0.09015719,  0.02417626,  0.00830836,  0.03181073,  0.13527542,
        0.08537893,  0.03187369,  0.00919137,  0.00857778,  0.01750316,
        0.11424149,  0.28841687,  0.10881213,  0.00761623,  0.02074611,
        0.01201022,  0.00550017])
</code></pre>
</div>

<p>We now create a ramdon forest only using those features. Let’s first select the corresponding columns.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">cols</span> <span class="o">=</span> <span class="no">X_train</span><span class="p">.</span><span class="nf">columns</span><span class="p">[</span><span class="n">clf_rfc1</span><span class="p">.</span><span class="nf">feature_importances_</span><span class="o">&gt;=</span><span class="mi">0</span><span class="o">.</span><span class="mo">001</span><span class="p">]</span></code></pre></figure>

<p>We create the classifier now</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">rfc</span> <span class="o">=</span> <span class="no">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'entropy'</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'n_estimators'</span><span class="p">:[</span><span class="mi">300</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span> <span class="s1">'min_samples_leaf'</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]}</span>
<span class="n">clf_rfc2</span> <span class="o">=</span> <span class="n">bestClass</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="no">X_train</span><span class="p">[</span><span class="n">cols</span><span class="p">],</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span></code></pre></figure>

<p>Our new accuracy is</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_rfc2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">[</span><span class="n">cols</span><span class="p">]))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.82511210762331844
</code></pre>
</div>

<p>Wich is much better, let’s look at the learning curve for this model.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_rfc2</span><span class="p">,</span> <span class="s1">'Random Forest'</span><span class="p">,</span> <span class="no">X</span><span class="p">[</span><span class="n">cols</span><span class="p">],</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_194_0.png" alt="" /></p>

<h2 id="logistic-regression">Logistic Regression</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> classifier predicts the probability of the outcome. More detailed info [here].</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">linear_model</span> <span class="n">import</span> <span class="no">LogisticRegression</span>
<span class="n">lg</span> <span class="o">=</span> <span class="no">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">'l1'</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'C'</span><span class="p">:[</span><span class="mi">0</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="o">.</span><span class="mi">8</span><span class="p">]}</span>
<span class="n">clf_lg</span> <span class="o">=</span> <span class="n">bestClass</span><span class="p">(</span><span class="n">lg</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span></code></pre></figure>

<p>We get an accuracy of</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_lg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.83856502242152464
</code></pre>
</div>

<p>And a learning curve:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_lg</span><span class="p">,</span> <span class="s1">'Logistic Regression'</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_201_0.png" alt="" /></p>

<h2 id="support-vector-machine-svm">Support Vector Machine (SVM)</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Support_vector_machine">SVM</a> classifier finds the best hyperplane separating the points on the class survived=True from the class survived=False. As this is not always possible the classifier usually relies on the Kernel trick, the problem being that it increases dimentionality. This classifier should run quite slowly and usually some data preparation needs to be used to reduce dimensionality (PCA for example) more info [here].</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">svm</span> <span class="n">import</span> <span class="no">SVC</span>
<span class="n">svc</span> <span class="o">=</span> <span class="no">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">'poly'</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">35</span><span class="p">],</span> <span class="s1">'gamma'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="o">.</span><span class="mo">0055</span><span class="p">,</span><span class="mi">0</span><span class="o">.</span><span class="mo">001</span><span class="p">],</span> <span class="s1">'coef0'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="o">.</span><span class="mi">2</span><span class="p">],</span>
              <span class="s1">'degree'</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}</span>
<span class="n">clf_svc</span> <span class="o">=</span> <span class="n">bestClass</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="p">)</span></code></pre></figure>

<p>Let’s check the accuracy</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_svc</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.8340807174887892
</code></pre>
</div>

<p>And the learning curve</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_svc</span><span class="p">,</span> <span class="s1">'SVC'</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_208_0.png" alt="" /></p>

<h2 id="voting-classifier">Voting Classifier</h2>

<p>The <a href="http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier">voting classifier</a> submits the classification to vote among other classifiers, more info [here]. It is part of the ensemble classifiers, we use the classifiers we have already and submit them to this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">ensemble</span> <span class="n">import</span> <span class="no">VotingClassifier</span>
<span class="n">clf_vc</span> <span class="o">=</span> <span class="no">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[</span> <span class="p">(</span><span class="s1">'lg'</span><span class="p">,</span> <span class="n">clf_lg</span><span class="p">),</span> <span class="p">(</span><span class="s1">'svc'</span><span class="p">,</span> <span class="n">clf_svc</span><span class="p">),</span> 
                                      <span class="p">(</span><span class="s1">'rfc1'</span><span class="p">,</span> <span class="n">clf_rfc1</span><span class="p">),(</span><span class="s1">'rfc2'</span><span class="p">,</span> <span class="n">clf_rfc2</span><span class="p">),</span> <span class="p">(</span><span class="s1">'knn'</span><span class="p">,</span> <span class="n">clf_knn</span><span class="p">)],</span> 
                          <span class="n">voting</span><span class="o">=</span><span class="s1">'hard'</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">clf_vc</span> <span class="o">=</span> <span class="n">clf_vc</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span> <span class="no">Y_train</span><span class="p">)</span></code></pre></figure>

<p>We get an accuracy of</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">accuracy_score</span><span class="p">(</span><span class="no">Y_test</span><span class="p">,</span> <span class="n">clf_vc</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X_test</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>0.82959641255605376
</code></pre>
</div>

<p>And a learning curve</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_vc</span><span class="p">,</span> <span class="s1">'Voting Classifier'</span><span class="p">,</span> <span class="no">X</span><span class="p">,</span> <span class="no">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Titanic_files/Titanic_215_0.png" alt="" /></p>

<h1 id="conclusion">Conclusion</h1>

<p>We can create classifiers that predict survival with an accuracy &gt; .8.</p>

<h1 id="submission">Submission</h1>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">test</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">PassengerId</span> <span class="o">=</span> <span class="nb">test</span><span class="o">.</span><span class="no">PassengerId</span>
<span class="nb">test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s1">'PassengerId'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="no">True</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">submission</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="no">X</span><span class="p">):</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'PassengerId'</span><span class="p">,</span> <span class="s1">'Survived'</span><span class="p">])</span>
    <span class="n">ans</span><span class="o">.</span><span class="no">PassengerId</span> <span class="o">=</span> <span class="no">PassengerId</span>
    <span class="n">ans</span><span class="o">.</span><span class="no">Survived</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="no">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="no">X</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">ans</span><span class="p">.</span><span class="nf">index</span><span class="p">)</span>
    <span class="n">ans</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="no">False</span><span class="p">)</span>
<span class="n">submission</span><span class="p">(</span><span class="n">clf_vc</span><span class="p">,</span><span class="s1">'submission.csv'</span><span class="p">,</span><span class="nb">test</span><span class="p">)</span></code></pre></figure>



  <!-- POST NAVIGATION -->
  <div class="postNav clearfix">
      
      
      <a class="next" href="/blog/neural-nets/"><span>Neural Networks&nbsp;&raquo;</span>
       
      </a>
     
  </div>
</div>

      	</div>
      	
      	


	</div><!-- end .content -->


   <div class="footer">
   <div class="container">
      <p class="copy">&copy; 2016 <a href="https://scy1505.github.io">Felipe Pérez.</a> Powered by <a href="http://jekyllrb.com">Jekyll</a></p>

      <div class="footer-links"> 
         <ul class="noList"> 
            
            <li><a href="https://www.facebook.com/juan1505">
                  <svg id="facebook-square" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M82.667,1H17.335C8.351,1,1,8.351,1,17.336v65.329c0,8.99,7.351,16.335,16.334,16.335h65.332 C91.652,99.001,99,91.655,99,82.665V17.337C99,8.353,91.652,1.001,82.667,1L82.667,1z M84.318,50H68.375v42.875H50V50h-8.855V35.973 H50v-9.11c0-12.378,5.339-19.739,19.894-19.739h16.772V22.3H72.967c-4.066-0.007-4.57,2.12-4.57,6.078l-0.023,7.594H86.75 l-2.431,14.027V50z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://twitter.com/jperezvallejo">
                  <svg id="twitter" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M99.001,19.428c-3.606,1.608-7.48,2.695-11.547,3.184c4.15-2.503,7.338-6.466,8.841-11.189 c-3.885,2.318-8.187,4-12.768,4.908c-3.667-3.931-8.893-6.387-14.676-6.387c-11.104,0-20.107,9.054-20.107,20.223 c0,1.585,0.177,3.128,0.52,4.609c-16.71-0.845-31.525-8.895-41.442-21.131C6.092,16.633,5.1,20.107,5.1,23.813 c0,7.017,3.55,13.208,8.945,16.834c-3.296-0.104-6.397-1.014-9.106-2.529c-0.002,0.085-0.002,0.17-0.002,0.255 c0,9.799,6.931,17.972,16.129,19.831c-1.688,0.463-3.463,0.71-5.297,0.71c-1.296,0-2.555-0.127-3.783-0.363 c2.559,8.034,9.984,13.882,18.782,14.045c-6.881,5.424-15.551,8.657-24.971,8.657c-1.623,0-3.223-0.096-4.796-0.282 c8.898,5.738,19.467,9.087,30.82,9.087c36.982,0,57.206-30.817,57.206-57.543c0-0.877-0.02-1.748-0.059-2.617 C92.896,27.045,96.305,23.482,99.001,19.428z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://github.com/scy1505">
                  <svg id="github" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M79.099,79.099 c-3.782,3.782-8.184,6.75-13.083,8.823c-1.245,0.526-2.509,0.989-3.79,1.387v-7.344c0-3.86-1.324-6.699-3.972-8.517 c1.659-0.16,3.182-0.383,4.57-0.67c1.388-0.287,2.855-0.702,4.402-1.245c1.547-0.543,2.935-1.189,4.163-1.938 c1.228-0.75,2.409-1.723,3.541-2.919s2.082-2.552,2.847-4.067s1.372-3.334,1.818-5.455c0.446-2.121,0.67-4.458,0.67-7.01 c0-4.945-1.611-9.155-4.833-12.633c1.467-3.828,1.308-7.991-0.478-12.489l-1.197-0.143c-0.829-0.096-2.321,0.255-4.474,1.053 c-2.153,0.798-4.57,2.105-7.249,3.924c-3.797-1.053-7.736-1.579-11.82-1.579c-4.115,0-8.039,0.526-11.772,1.579 c-1.69-1.149-3.294-2.097-4.809-2.847c-1.515-0.75-2.727-1.26-3.637-1.532c-0.909-0.271-1.754-0.439-2.536-0.503 c-0.782-0.064-1.284-0.079-1.507-0.048c-0.223,0.031-0.383,0.064-0.478,0.096c-1.787,4.53-1.946,8.694-0.478,12.489 c-3.222,3.477-4.833,7.688-4.833,12.633c0,2.552,0.223,4.889,0.67,7.01c0.447,2.121,1.053,3.94,1.818,5.455 c0.765,1.515,1.715,2.871,2.847,4.067s2.313,2.169,3.541,2.919c1.228,0.751,2.616,1.396,4.163,1.938 c1.547,0.543,3.014,0.957,4.402,1.245c1.388,0.287,2.911,0.511,4.57,0.67c-2.616,1.787-3.924,4.626-3.924,8.517v7.487 c-1.445-0.43-2.869-0.938-4.268-1.53c-4.899-2.073-9.301-5.041-13.083-8.823c-3.782-3.782-6.75-8.184-8.823-13.083 C9.934,60.948,8.847,55.56,8.847,50s1.087-10.948,3.231-16.016c2.073-4.899,5.041-9.301,8.823-13.083s8.184-6.75,13.083-8.823 C39.052,9.934,44.44,8.847,50,8.847s10.948,1.087,16.016,3.231c4.9,2.073,9.301,5.041,13.083,8.823 c3.782,3.782,6.75,8.184,8.823,13.083c2.143,5.069,3.23,10.457,3.23,16.016s-1.087,10.948-3.231,16.016 C85.848,70.915,82.88,75.317,79.099,79.099L79.099,79.099z"></path>
                  </svg>
            </a></li>
             
            
            <li><a href="mailto:juan1505@gmail.com">
                  <svg id="mail" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M25.5,25.5h49 c0.874,0,1.723,0.188,2.502,0.542L50,57.544L22.998,26.041C23.777,25.687,24.626,25.499,25.5,25.5L25.5,25.5z M19.375,68.375v-36.75 c0-0.128,0.005-0.256,0.014-0.383l17.96,20.953L19.587,69.958C19.448,69.447,19.376,68.916,19.375,68.375L19.375,68.375z M74.5,74.5 h-49c-0.541,0-1.072-0.073-1.583-0.212l17.429-17.429L50,66.956l8.653-10.096l17.429,17.429C75.572,74.427,75.041,74.5,74.5,74.5 L74.5,74.5z M80.625,68.375c0,0.541-0.073,1.072-0.211,1.583L62.652,52.195l17.96-20.953c0.008,0.127,0.014,0.255,0.014,0.383 L80.625,68.375L80.625,68.375z"></path>
                  </svg>
            </a></li>
            
         </ul>
      </div>
   </div>
</div><!-- end .footer -->


  
   <!-- Add jQuery and other scripts -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src=""><\/script>')</script>
<script src="/assets/js/dropcap.min.js"></script>
<script src="/assets/js/responsive-nav.min.js"></script>
<script src="/assets/js/scripts.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



</body>

</html>
