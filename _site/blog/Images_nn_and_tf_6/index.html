<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"><![endif]-->
<!--[if IE 7]><html class="no-js lt-ie9 lt-ie8" <![endif]-->
<!--[if IE 8]><html class="no-js lt-ie9" <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>NN for image reccognition - Convolutional Network</title>

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="/assets/img/favicon.ico" />

    <!-- Come and get me RSS readers -->
    <link rel="alternate" type="application/rss+xml" title="Felipe's Place" href="http://scy1505.github.io/feed.xml" />
    
    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/style.css">
    <!--[if IE 8]><link rel="stylesheet" href="/assets/css/ie.css"><![endif]-->
    <link rel="canonical" href="http://scy1505.github.io/blog/Images_nn_and_tf_6/">

    <!-- Modernizr -->
    <script src="/assets/js/modernizr.custom.15390.js" type="text/javascript"></script>

     <!-- Google Analytics: change UA-XXXXX-X to be your site's ID. -->
<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-58263416-1', 'auto');
ga('send', 'pageview');

</script>
 
</head>


<body>

	 <div class="header">
     <div class="container">
         <h1 class="logo"><a href="/"> <font color="#5B0000">Felipe's Place</font></a></h1>
         <nav class="nav-collapse">
             <ul class="noList">
                 
                 <li class="element first  ">
                     <a href="/index.html">Home</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/about">About</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/contact">Contact</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/research">Research</a>
                 </li> 
                 
                 <li class="element   last">
                     <a href="/articles">Posts</a>
                 </li> 
                 
                 <!--<li>
                     <a href="/articles">Posts</a>
                 </li>-->
                 <li> <a href="https://github.com/scy1505" target="_blank">GitHub</a></li>
                 <!-- <li><a href="https://github.com/brianmaierjr/long-haul/archive/master.zip">Download Theme</a></li> -->
             </ul>
         </nav>
     </div>
 </div><!-- end .header -->


   	<div class="content">

   		
		 <div class="container">
        	 <div class="post">
  
  <h1 class="postTitle">NN for image reccognition - Convolutional Network</h1>
  <p class="meta">January 23, 2017 | <span class="time">17</span> Minute Read</p>
  
  <p>This is part 6 of our blogpost related with images and tensorflow. The posts follow the following:</p>

<ol>
  <li><a href="/blog/Images_nn_and_tf_1/">Getting the Data</a>.</li>
  <li><a href="/blog/Images_nn_and_tf_2/">k-neareast Neighbor</a>.</li>
  <li><a href="/blog/Images_nn_and_tf_3/">Logistic Regression</a>.</li>
  <li><a href="/blog/Images_nn_and_tf_4/">A two layer Neural Network</a>.</li>
  <li><a href="/blog/Images_nn_and_tf_5/">Convolutions in Tensorflow</a>.</li>
  <li><strong>Convolutional Network.</strong></li>
</ol>

<h1 id="convolutional-networks">Convolutional Networks.</h1>

<p>Before dwelling into this post, I recommend that you read the module two of the excellent introductory course <a href="http://cs231n.github.io/">CS231n</a>.</p>

<p>In this, our last post of this series, we develop a convolutional network to attack the image classificiation of CIFAR10. There are many resources and results out there, some of them reaching high accuracy. In order to make things simple, we have a more naive approach. But we include some of the features we have seen before together with some new ones.</p>

<ul>
  <li>We keep sizes small for practical purposes.</li>
  <li>We create wrappers to have a cleaner code.</li>
  <li>Preprocess of image.</li>
  <li>We use Tensorboard to create summaries of our results.</li>
  <li>We use Decay Rate or adamOptimizer?</li>
  <li>We include maxpooling.</li>
  <li>We include dropout.</li>
  <li>We include code for saving the trained weights.</li>
</ul>

<h2 id="preparations">Preparations</h2>

<p>We load the necessary libraries</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">tensorflow</span> <span class="n">as</span> <span class="n">tf</span>
<span class="n">from</span> <span class="n">matplotlib</span> <span class="n">import</span> <span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">import</span> <span class="n">aux</span></code></pre></figure>

<p>and import the data</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="no">X_test</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span><span class="n">aux</span><span class="p">.</span><span class="nf">input</span><span class="p">(</span><span class="n">flat</span><span class="o">=</span><span class="no">False</span><span class="p">)</span></code></pre></figure>

<p>And, as before we modify our labels</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">y_train</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">==</span><span class="n">y_train</span><span class="p">[:,</span><span class="no">None</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">)</span>
<span class="n">y_test</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">==</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_test</span><span class="p">)[:,</span><span class="no">None</span><span class="p">]).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">)</span></code></pre></figure>

<h1 id="preprocess-image">Preprocess Image</h1>

<p>There are many operations that can be done here to preprocess an image (image augmentation, blurring,etc.) We opt only for normalizing the images in each channel. That is we fix each channel, and each pixel, and compute</p>

<script type="math/tex; mode=display">\frac{x-\text{E}[x]}{\sigma[x]+\epsilon}</script>

<p>We first compute the mean and standard deviation for each entry</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="no">X_train</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code></pre></figure>

<p>And then normalize the train and testing data</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X_train</span><span class="o">=</span> <span class="p">(</span><span class="no">X_train</span><span class="o">-</span><span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">std</span><span class="o">+</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">16</span><span class="p">)</span>
<span class="no">X_test</span><span class="o">=</span> <span class="p">(</span><span class="no">X_test</span><span class="o">-</span><span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">std</span><span class="o">+</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">16</span><span class="p">)</span></code></pre></figure>

<h1 id="the-network">The Network</h1>

<p>We are ready to begin creating our network. We need to decide on a style, so we go for</p>

<p style="text-align: center;"><b>INPUT -&gt; [CONV -&gt; RELU -&gt; MAXPOOL]*2 -&gt; FULLY CONNECTED -&gt; RELU -&gt; FULLY CONNECTED</b></p>

<p>We need to create placeholders to hold the imput, then we will have two layers consisting of a convolutional network with rectified linear unit activations and a max pool. We follow by a fully connected network with rectified linear output and we finish with a fully coneceted netwkork with sigmoid activation. It is important that we keep track of the different sizes.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Tensor</strong></th>
      <th style="text-align: center"><strong>Size</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Input</td>
      <td style="text-align: center">32x32x3</td>
    </tr>
    <tr>
      <td style="text-align: center">After First Convolution</td>
      <td style="text-align: center">32x32x16</td>
    </tr>
    <tr>
      <td style="text-align: center">After Second Convolution</td>
      <td style="text-align: center">32x32x32</td>
    </tr>
  </tbody>
</table>

<p>Double check, I don’t think this is right, because of max pool!</p>

<h1 id="the-global-parameters">The global parameters</h1>

<p>It is a good idea to keep the global parameters as constants. A question is what global parameters we need.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Training Parameters</span>
<span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">001</span>
<span class="n">epochs</span><span class="o">=</span><span class="mi">1001</span>
<span class="n">display_step</span><span class="o">=</span><span class="mi">1000</span>


<span class="c1">#Network Parameters</span>
<span class="n">n_input</span><span class="o">=</span><span class="n">len</span><span class="p">(</span><span class="no">X_train</span><span class="p">)</span>
<span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span>
<span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">75</span>

<span class="c1">#The tensor keeping the dropout probability.</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">)</span>

<span class="c1">#A path for saving the log files for TensorBoard</span>
<span class="n">logs_path</span> <span class="o">=</span> <span class="s1">'./conv_logs/'</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s2">"./conv_model/model.ckpt"</span></code></pre></figure>

<h2 id="the-placeholders">The Placeholders</h2>

<p>We create the placeholders that holds our data.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">X_train_tf</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">l2_normalize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">,</span> <span class="p">[</span><span class="no">None</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="nb">name</span><span class="o">=</span><span class="s1">'X_train'</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="no">X_test_tf</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">,</span> <span class="p">[</span><span class="no">None</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="nb">name</span><span class="o">=</span><span class="s1">'X_test'</span><span class="p">)</span>
<span class="n">y_train_tf</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">,[</span><span class="no">None</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span><span class="nb">name</span><span class="o">=</span><span class="s1">'y_train'</span><span class="p">)</span>
<span class="n">y_test_tf</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">,[</span><span class="no">None</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span><span class="nb">name</span><span class="o">=</span><span class="s1">'y_test'</span><span class="p">)</span></code></pre></figure>

<h1 id="the-convolution-matrices">The Convolution Matrices</h1>

<p>We have two convolution layers, hence we need two convolution matrices</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">weights</span><span class="o">=</span><span class="p">{}</span>

<span class="c1"># 3x3 conv, 3 input, 16 outputs</span>
<span class="n">weights</span><span class="p">[</span><span class="s1">'wc1'</span><span class="p">]</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'wc1'</span><span class="p">)</span>

<span class="c1"># 5x5 conv, 16 inputs, 32 outputs</span>
<span class="n">weights</span><span class="p">[</span><span class="s1">'wc2'</span><span class="p">]</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'wc2'</span><span class="p">)</span></code></pre></figure>

<h1 id="the-later-layer-weights">The Later Layer Weights</h1>

<p>We also need the weights for the matrix in the connected layer. Note that the two max pooling reduce the size of the tensor from 32x32 to 8x8.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># fully connected, 8*8*32 inputs, 1024 outputs</span>
<span class="n">weights</span><span class="p">[</span><span class="s1">'wd1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">8</span><span class="o">*</span><span class="mi">8</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'wd1'</span><span class="p">)</span>

<span class="c1"># # 1024 inputs, 10 outputs (class prediction)</span>
<span class="n">weights</span><span class="p">[</span><span class="s1">'out'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'wout'</span><span class="p">)</span></code></pre></figure>

<h1 id="the-biases-vectors">The Biases Vectors</h1>

<p>Each layer needs a bias vector</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'bc1'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">16</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'bc1'</span><span class="p">),</span>
    <span class="s1">'bc2'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">32</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'bc2'</span><span class="p">),</span>
    <span class="s1">'bd1'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">256</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'bd1'</span><span class="p">),</span>
    <span class="s1">'out'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="no">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="n">n_classes</span><span class="p">]),</span><span class="nb">name</span><span class="o">=</span><span class="s1">'bout'</span><span class="p">)</span>
<span class="p">}</span></code></pre></figure>

<h1 id="the-network-wrappers">The Network wrappers</h1>

<p>We want our network to be easy to read, understand, and debug, we use wrappers to acchieve this. In particular, we wrap the layers, which each consists of a convulational part and a relu activation function, and in some cases a maxpool.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Create some wrappers for simplicity</span>
<span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="no">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Conv2D wrapper, with bias and relu activation</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="no">W</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">bias_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">maxpool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># MaxPool2D wrapper</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                          <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span></code></pre></figure>

<h1 id="the-network-code">The Network code</h1>

<p>We are ready to have our main code.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>

    <span class="c1"># Convolution Layer 1</span>
    <span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Convolution_1'</span><span class="p">):</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">'wc1'</span><span class="p">],</span> <span class="n">biases</span><span class="p">[</span><span class="s1">'bc1'</span><span class="p">])</span>
        <span class="c1"># Max Pooling (down-sampling)</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">maxpool2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Convolution_2'</span><span class="p">):</span>    
        <span class="c1"># Convolution Layer</span>
        <span class="n">conv2</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">'wc2'</span><span class="p">],</span> <span class="n">biases</span><span class="p">[</span><span class="s1">'bc2'</span><span class="p">])</span>
        <span class="c1"># Max Pooling (down-sampling)</span>
        <span class="n">conv2</span> <span class="o">=</span> <span class="n">maxpool2d</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Fully_Connected'</span><span class="p">):</span>
        <span class="c1"># Fully connected layer</span>
        <span class="c1"># Reshape conv2 output to fit fully connected layer input</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">'wd1'</span><span class="p">].</span><span class="nf">get_shape</span><span class="p">().</span><span class="nf">as_list</span><span class="p">()[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">'wd1'</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">'bd1'</span><span class="p">])</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">fc1</span><span class="p">)</span>
        
        <span class="c1"># Apply Dropout</span>
        <span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Dropout'</span><span class="p">):</span>
            <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="c1"># Output, class prediction</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s1">'out'</span><span class="p">]),</span> <span class="n">biases</span><span class="p">[</span><span class="s1">'out'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Model'</span><span class="p">):</span>
    <span class="c1"># Construct model</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="no">X_train_tf</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span></code></pre></figure>

<h1 id="loss-function-optimizer-and-accuracy">Loss function, Optimizer, and Accuracy</h1>

<p>We use cross entropy with logits for the lost function and the Adam Optimizer for updating the weights.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">):</span>
    <span class="c1">#Define the cost function</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">nn</span><span class="p">.</span><span class="nf">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_train_tf</span><span class="p">))</span>

<span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Optimizer'</span><span class="p">):</span>
    <span class="c1">#Defines the optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">train</span><span class="o">.</span><span class="no">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">).</span><span class="nf">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="n">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">):</span>    
    <span class="c1"># Evaluate model</span>
    <span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">equal</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">y_train_tf</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">))</span></code></pre></figure>

<h1 id="evaluating-the-model">Evaluating the model</h1>

<p>We initialize the variables</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Initializing the variables</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">global_variables_initializer</span><span class="p">()</span></code></pre></figure>

<p>And create some summaries and the op for putting them together.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1">#We keep track of the cost and accuracy</span>
<span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="p">.</span><span class="nf">scalar</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="p">.</span><span class="nf">scalar</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>


<span class="c1"># Create summaries to visualize weights</span>
<span class="k">for</span> <span class="n">var</span> <span class="k">in</span> <span class="n">tf</span><span class="p">.</span><span class="nf">trainable_variables</span><span class="p">():</span>
    <span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="n">var</span><span class="p">.</span><span class="nf">name</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
    

<span class="c1"># The op for merging the summaries</span>
<span class="n">merged_summary_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="p">.</span><span class="nf">merge_all</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>INFO:tensorflow:Summary name wc1:0 is illegal; using wc1_0 instead.
INFO:tensorflow:Summary name wc2:0 is illegal; using wc2_0 instead.
INFO:tensorflow:Summary name wd1:0 is illegal; using wd1_0 instead.
INFO:tensorflow:Summary name wout:0 is illegal; using wout_0 instead.
INFO:tensorflow:Summary name bc1:0 is illegal; using bc1_0 instead.
INFO:tensorflow:Summary name bc2:0 is illegal; using bc2_0 instead.
INFO:tensorflow:Summary name bd1:0 is illegal; using bd1_0 instead.
INFO:tensorflow:Summary name bout:0 is illegal; using bout_0 instead.
</code></pre>
</div>

<p>As we want to reuse the values we get in the variables, we need an operation for saving.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># 'Saver' op to save and restore all the variables</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">train</span><span class="o">.</span><span class="no">Saver</span><span class="p">()</span></code></pre></figure>

<p>Finally, we run our model, we will just use a small set of data. (If you have a GPU you can run the model on the whole dataset for a couple of weeks to get a nice result)</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># We get only one fifth of the data.</span>
<span class="n">n_input</span><span class="o">=</span><span class="mi">1500</span>

<span class="c1"># Launch the graph</span>
<span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="no">Session</span><span class="p">()</span> <span class="n">as</span> <span class="ss">sess:
    </span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    
     <span class="c1"># op to write logs to Tensorboard</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="o">.</span><span class="no">FileWriter</span><span class="p">(</span><span class="n">logs_path</span><span class="p">,</span>
                                            <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">get_default_graph</span><span class="p">())</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'\r This is epoch %d'</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="k">end</span><span class="o">=</span><span class="s1">'. '</span><span class="p">)</span>
        <span class="n">indexes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n_input</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span>
        <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="no">X_train_tf</span><span class="ss">:X_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span><span class="n">y_train_tf</span><span class="ss">:y_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span><span class="ss">keep_prob: </span><span class="n">dropout</span><span class="p">})</span>
    

        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="n">display_step</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate batch loss and accuracy</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span><span class="n">summary</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span><span class="n">merged_summary_op</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="no">X_train_tf</span><span class="p">:</span> <span class="no">X_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span>
                                                              <span class="ss">y_train_tf: </span><span class="n">y_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span>
                                                              <span class="ss">keep_prob: </span><span class="mi">1</span><span class="o">.</span><span class="mi">0</span> <span class="p">})</span>
            <span class="n">summary_writer</span><span class="p">.</span><span class="nf">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Minibatch Loss= "</span> <span class="o">+</span> <span class="p">\</span>
                  <span class="s2">"{:.6f}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">+</span> <span class="s2">", Training Accuracy= "</span> <span class="o">+</span> <span class="p">\</span>
                  <span class="s2">"{:.5f}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
            
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved in file: %s"</span> <span class="o">%</span> <span class="n">save_path</span><span class="p">)</span>
            
    
   </code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code> This is epoch 0. Minibatch Loss= 38566.578125, Training Accuracy= 0.08600
 This is epoch 1000. Minibatch Loss= 3.023288, Training Accuracy= 0.28600
Model saved in file: ./conv_model/model.ckpt
</code></pre>
</div>

<p>As we saved our model, we could reuse it and run many more epochs. For example we could (but don’t) use the following.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">epochs</span><span class="o">=</span><span class="mi">2001</span>
<span class="n">display_step</span><span class="o">=</span><span class="mi">200</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Launch the graph</span>
<span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="no">Session</span><span class="p">()</span> <span class="n">as</span> <span class="ss">sess:
    </span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    
    
    <span class="c1"># Restore model weights from previously saved model</span>
    <span class="n">load_path</span> <span class="o">=</span> <span class="n">saver</span><span class="p">.</span><span class="nf">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model restored from file: %s"</span> <span class="o">%</span> <span class="n">save_path</span><span class="p">)</span>
    
    
     <span class="c1"># op to write logs to Tensorboard</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">summary</span><span class="o">.</span><span class="no">FileWriter</span><span class="p">(</span><span class="n">logs_path</span><span class="p">,</span>
                                            <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="nf">get_default_graph</span><span class="p">())</span>
    
    
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'\r This is epoch %d'</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1001</span><span class="p">),</span> <span class="k">end</span><span class="o">=</span><span class="s1">'. '</span><span class="p">)</span>
        <span class="n">indexes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n_input</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span>
        <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="no">X_train_tf</span><span class="ss">:X_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span><span class="n">y_train_tf</span><span class="ss">:y_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span><span class="ss">keep_prob: </span><span class="n">dropout</span><span class="p">})</span>
        

        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="n">display_step</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate batch loss and accuracy</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span><span class="n">summary</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span><span class="n">merged_summary_op</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="no">X_train_tf</span><span class="p">:</span> <span class="no">X_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span>
                                                              <span class="ss">y_train_tf: </span><span class="n">y_train</span><span class="p">[</span><span class="ss">:n_input</span><span class="p">][</span><span class="n">indexes</span><span class="p">],</span>
                                                              <span class="ss">keep_prob: </span><span class="mi">1</span><span class="o">.</span><span class="p">})</span>
            <span class="n">summary_writer</span><span class="p">.</span><span class="nf">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Minibatch Loss= "</span> <span class="o">+</span> <span class="p">\</span>
                  <span class="s2">"{:.6f}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">+</span> <span class="s2">", Training Accuracy= "</span> <span class="o">+</span> <span class="p">\</span>
                  <span class="s2">"{:.5f}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
            
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved in file: %s"</span> <span class="o">%</span> <span class="n">save_path</span><span class="p">)</span>
              </code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>Model restored from file: ./conv_model/model.ckpt
 This is epoch 1001. Minibatch Loss= 2.520611, Training Accuracy= 0.31200
 This is epoch 1201. Minibatch Loss= 1.945457, Training Accuracy= 0.29000
 This is epoch 1401. Minibatch Loss= 1.890653, Training Accuracy= 0.28400
 This is epoch 1601. Minibatch Loss= 1.898642, Training Accuracy= 0.26600
 This is epoch 1801. Minibatch Loss= 1.908458, Training Accuracy= 0.25400
 This is epoch 2001. Minibatch Loss= 1.848357, Training Accuracy= 0.28200
 This is epoch 2201. Minibatch Loss= 1.952290, Training Accuracy= 0.25000
 This is epoch 2401. Minibatch Loss= 1.889921, Training Accuracy= 0.26000
 This is epoch 2601. Minibatch Loss= 1.880741, Training Accuracy= 0.28200
 This is epoch 2801. Minibatch Loss= 1.920311, Training Accuracy= 0.24600
 This is epoch 3001. Minibatch Loss= 1.870832, Training Accuracy= 0.27800
Model saved in file: ./conv_model/model.ckpt
</code></pre>
</div>

<p>We finish by using our trained model to predict the results in the testing data</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="no">Session</span><span class="p">()</span> <span class="n">as</span> <span class="ss">sess:
    </span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    
    
    <span class="c1"># Restore model weights from previously saved model</span>
    <span class="n">load_path</span> <span class="o">=</span> <span class="n">saver</span><span class="p">.</span><span class="nf">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model restored from file: %s"</span> <span class="o">%</span> <span class="n">save_path</span><span class="p">)</span>
    
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="no">X_test_tf</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">correct_pred_test</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">equal</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">pred_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">y_test_tf</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">correct_pred_test</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="nf">float32</span><span class="p">))</span>
    
    <span class="n">acc</span><span class="o">=</span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">accuracy_test</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="no">X_test_tf</span><span class="p">:</span> <span class="no">X_test</span><span class="p">,</span><span class="ss">y_test_tf: </span><span class="n">y_test</span><span class="p">,</span><span class="ss">keep_prob: </span><span class="mi">1</span><span class="o">.</span><span class="p">})</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The accuracy for the test set is %.3f'</span><span class="o">%</span><span class="n">acc</span><span class="p">)</span>
    </code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>Model restored from file: ./conv_model/model.ckpt
The accuracy for the test set is 0.149
</code></pre>
</div>

<h1 id="whats-next">What’s next?</h1>

<p>You should learn to use GPU. Explore imagenet, use pretrained models and adapt them to yours, learn Keras. Study NPL problems, Recurrent Networks, etc. There are many things to learn, and many examples online.</p>

<p>Finally, you should check out <a href="https://www.youtube.com/watch?v=u6aEYuemt0M">this awesome lecture</a>.</p>


  <!-- POST NAVIGATION -->
  <div class="postNav clearfix">
     
      <a class="prev" href="/blog/Images_nn_and_tf_5/"><span>&laquo;&nbsp;NN for image reccognition - Convolutions in Tensorflow</span>
      
    </a>
      
     
  </div>
</div>

      	</div>
      	
      	


	</div><!-- end .content -->


   <div class="footer">
   <div class="container">
      <p class="copy">&copy; 2017 <a href="https://scy1505.github.io">Felipe Pérez.</a> Powered by <a href="http://jekyllrb.com">Jekyll</a></p>

      <div class="footer-links"> 
         <ul class="noList"> 
            
            <li><a href="https://www.facebook.com/juan1505">
                  <svg id="facebook-square" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M82.667,1H17.335C8.351,1,1,8.351,1,17.336v65.329c0,8.99,7.351,16.335,16.334,16.335h65.332 C91.652,99.001,99,91.655,99,82.665V17.337C99,8.353,91.652,1.001,82.667,1L82.667,1z M84.318,50H68.375v42.875H50V50h-8.855V35.973 H50v-9.11c0-12.378,5.339-19.739,19.894-19.739h16.772V22.3H72.967c-4.066-0.007-4.57,2.12-4.57,6.078l-0.023,7.594H86.75 l-2.431,14.027V50z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://twitter.com/jperezvallejo">
                  <svg id="twitter" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M99.001,19.428c-3.606,1.608-7.48,2.695-11.547,3.184c4.15-2.503,7.338-6.466,8.841-11.189 c-3.885,2.318-8.187,4-12.768,4.908c-3.667-3.931-8.893-6.387-14.676-6.387c-11.104,0-20.107,9.054-20.107,20.223 c0,1.585,0.177,3.128,0.52,4.609c-16.71-0.845-31.525-8.895-41.442-21.131C6.092,16.633,5.1,20.107,5.1,23.813 c0,7.017,3.55,13.208,8.945,16.834c-3.296-0.104-6.397-1.014-9.106-2.529c-0.002,0.085-0.002,0.17-0.002,0.255 c0,9.799,6.931,17.972,16.129,19.831c-1.688,0.463-3.463,0.71-5.297,0.71c-1.296,0-2.555-0.127-3.783-0.363 c2.559,8.034,9.984,13.882,18.782,14.045c-6.881,5.424-15.551,8.657-24.971,8.657c-1.623,0-3.223-0.096-4.796-0.282 c8.898,5.738,19.467,9.087,30.82,9.087c36.982,0,57.206-30.817,57.206-57.543c0-0.877-0.02-1.748-0.059-2.617 C92.896,27.045,96.305,23.482,99.001,19.428z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://github.com/scy1505">
                  <svg id="github" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M79.099,79.099 c-3.782,3.782-8.184,6.75-13.083,8.823c-1.245,0.526-2.509,0.989-3.79,1.387v-7.344c0-3.86-1.324-6.699-3.972-8.517 c1.659-0.16,3.182-0.383,4.57-0.67c1.388-0.287,2.855-0.702,4.402-1.245c1.547-0.543,2.935-1.189,4.163-1.938 c1.228-0.75,2.409-1.723,3.541-2.919s2.082-2.552,2.847-4.067s1.372-3.334,1.818-5.455c0.446-2.121,0.67-4.458,0.67-7.01 c0-4.945-1.611-9.155-4.833-12.633c1.467-3.828,1.308-7.991-0.478-12.489l-1.197-0.143c-0.829-0.096-2.321,0.255-4.474,1.053 c-2.153,0.798-4.57,2.105-7.249,3.924c-3.797-1.053-7.736-1.579-11.82-1.579c-4.115,0-8.039,0.526-11.772,1.579 c-1.69-1.149-3.294-2.097-4.809-2.847c-1.515-0.75-2.727-1.26-3.637-1.532c-0.909-0.271-1.754-0.439-2.536-0.503 c-0.782-0.064-1.284-0.079-1.507-0.048c-0.223,0.031-0.383,0.064-0.478,0.096c-1.787,4.53-1.946,8.694-0.478,12.489 c-3.222,3.477-4.833,7.688-4.833,12.633c0,2.552,0.223,4.889,0.67,7.01c0.447,2.121,1.053,3.94,1.818,5.455 c0.765,1.515,1.715,2.871,2.847,4.067s2.313,2.169,3.541,2.919c1.228,0.751,2.616,1.396,4.163,1.938 c1.547,0.543,3.014,0.957,4.402,1.245c1.388,0.287,2.911,0.511,4.57,0.67c-2.616,1.787-3.924,4.626-3.924,8.517v7.487 c-1.445-0.43-2.869-0.938-4.268-1.53c-4.899-2.073-9.301-5.041-13.083-8.823c-3.782-3.782-6.75-8.184-8.823-13.083 C9.934,60.948,8.847,55.56,8.847,50s1.087-10.948,3.231-16.016c2.073-4.899,5.041-9.301,8.823-13.083s8.184-6.75,13.083-8.823 C39.052,9.934,44.44,8.847,50,8.847s10.948,1.087,16.016,3.231c4.9,2.073,9.301,5.041,13.083,8.823 c3.782,3.782,6.75,8.184,8.823,13.083c2.143,5.069,3.23,10.457,3.23,16.016s-1.087,10.948-3.231,16.016 C85.848,70.915,82.88,75.317,79.099,79.099L79.099,79.099z"></path>
                  </svg>
            </a></li>
             
            
            <li><a href="mailto:juan1505@gmail.com">
                  <svg id="mail" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M25.5,25.5h49 c0.874,0,1.723,0.188,2.502,0.542L50,57.544L22.998,26.041C23.777,25.687,24.626,25.499,25.5,25.5L25.5,25.5z M19.375,68.375v-36.75 c0-0.128,0.005-0.256,0.014-0.383l17.96,20.953L19.587,69.958C19.448,69.447,19.376,68.916,19.375,68.375L19.375,68.375z M74.5,74.5 h-49c-0.541,0-1.072-0.073-1.583-0.212l17.429-17.429L50,66.956l8.653-10.096l17.429,17.429C75.572,74.427,75.041,74.5,74.5,74.5 L74.5,74.5z M80.625,68.375c0,0.541-0.073,1.072-0.211,1.583L62.652,52.195l17.96-20.953c0.008,0.127,0.014,0.255,0.014,0.383 L80.625,68.375L80.625,68.375z"></path>
                  </svg>
            </a></li>
            
         </ul>
      </div>
   </div>
</div><!-- end .footer -->


  
   <!-- Add jQuery and other scripts -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src=""><\/script>')</script>
<script src="/assets/js/dropcap.min.js"></script>
<script src="/assets/js/responsive-nav.min.js"></script>
<script src="/assets/js/scripts.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



</body>

</html>
