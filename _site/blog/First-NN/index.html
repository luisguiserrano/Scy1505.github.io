<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"><![endif]-->
<!--[if IE 7]><html class="no-js lt-ie9 lt-ie8" <![endif]-->
<!--[if IE 8]><html class="no-js lt-ie9" <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <title>A Neural Networks from scratch</title>

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="/assets/img/favicon.ico" />

    <!-- Come and get me RSS readers -->
    <link rel="alternate" type="application/rss+xml" title="Puppy's Place" href="http://scy1505.github.io/feed.xml" />
    
    <!-- Stylesheet -->
    <link rel="stylesheet" href="/assets/css/style.css">
    <!--[if IE 8]><link rel="stylesheet" href="/assets/css/ie.css"><![endif]-->
    <link rel="canonical" href="http://scy1505.github.io/blog/First-NN/">

    <!-- Modernizr -->
    <script src="/assets/js/modernizr.custom.15390.js" type="text/javascript"></script>

     <!-- Google Analytics: change UA-XXXXX-X to be your site's ID. -->
<script>
   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-58263416-1', 'auto');
ga('send', 'pageview');

</script>
 
</head>


<body>

	 <div class="header">
     <div class="container">
         <h1 class="logo"><a href="/">Puppy's Place</a></h1>
         <nav class="nav-collapse">
             <ul class="noList">
                 
                 <li class="element first  ">
                     <a href="/index.html">Home</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/about">About</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/contact">Contact</a>
                 </li> 
                 
                 <li class="element   ">
                     <a href="/research">Research</a>
                 </li> 
                 
                 <li class="element   last">
                     <a href="/articles">Posts</a>
                 </li> 
                 
                 <!--<li>
                     <a href="/articles">Posts</a>
                 </li>-->
                 <li> <a href="https://github.com/scy1505" target="_blank">GitHub</a></li>
                 <!-- <li><a href="https://github.com/brianmaierjr/long-haul/archive/master.zip">Download Theme</a></li> -->
             </ul>
         </nav>
     </div>
 </div><!-- end .header -->


   	<div class="content">

   		
		 <div class="container">
        	 <div class="post">
  
  <h1 class="postTitle">A Neural Networks from scratch</h1>
  <p class="meta">October 20, 2016 | <span class="time">12</span> Minute Read</p>
  
  <p>We write a short and relly basic neural network. There are many from scracth neural networks outthere, one I particularly like is by <a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/">Denny Brtiz</a>.
Our goal is to build a three layer neural network. Where the first layer is the input layer, then we have the hidden layer and finally we get the output layer. To make our life easier and so we can visualize what’s going on we restrict our output to points in <script type="math/tex">\mathbb{R}^2</script> and out outputs to the set <script type="math/tex">\{0,1\}</script>.</p>

<p>Before diving into the procedure, let’s import the packages we will use.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Packages</span>
<span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="nf">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">matplotlib</span>

<span class="c1"># Display plots inline and change default figure size</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="nf">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="o">.</span><span class="mi">0</span><span class="p">)</span></code></pre></figure>

<h2 id="the-activation-function">The activation function</h2>

<p>In our previous notebook we used the logistic function <script type="math/tex">\varphi(x) = \frac{1}{1+e^{-x}}</script> as an activation function. The main reason for this choice is the fact that <script type="math/tex">\varphi'(x)=\varphi(x)(1-\varphi(x))</script>, which allows us to compute the weights of the neurons efficiently. But the sigmoid function has many drawbacks, one of them being that once the value at which activated is a little large, the slope of the gradient will be quite small, this makes gradient descent convergence to be quite slow. Lucklily there are some other function we can use that have a similar behavior, among them we have the hyperbolic tangent <script type="math/tex">\tanh(x)=\frac{e^{2x}-1}{e^{2x}+1}.</script> Note that <script type="math/tex">\tanh'(x)=1-\tanh^2(x)</script>.</p>

<h2 id="what-arguments-to-use">What arguments to use?</h2>

<p>In creating/training our neural network there are some variables involved. Say, the number of neurons, how many times we will go throught the training points, (aka the number of steps we are taking in the descend), are we doing full batch, mini-batch, or online version, and the learning rate. But, we are missing the most important part, the training Data!
We will get our training data “ramdomly”, we can do this via the models in sklearn and choose some data that is bad for binary threshold, say a circle inside a circle.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># Generate a dataset and plot it</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="p">.</span><span class="nf">datasets</span> <span class="n">import</span> <span class="n">make_circles</span>
<span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>
<span class="no">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_circles</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="no">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="no">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">cm</span><span class="o">.</span><span class="no">Set3</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/Our_first_NN_files/Our_first_NN_8_0.png" alt="" /></p>

<h2 id="the-output-doesnt-feel-right">The output doesn’t feel right</h2>

<p>And it shouldn’t. We want the output to be either 0 or 1, but the output neuron has an activation function given by <script type="math/tex">\varphi(x)</script> with continuous output in <script type="math/tex">(0,1)</script>, or an activation function <script type="math/tex">\tanh(x)</script> with continuous output in <script type="math/tex">(-1,1)</script>. How do we fix this? When classifying it is common to understand a continuous output as a probability (think logistic), so we only need to change our output to the interval <script type="math/tex">(0,1)</script>, there are several ways of doing this, for example using <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a>, using softmax introduces another problem for us, how to measure error! As we don’t want to worry about this, we just do a naive approach, we change our desired targets from <script type="math/tex">\{0,1\}</script> to <script type="math/tex">\{-1,1\}</script>.</p>

<h2 id="some-notation">Some notation</h2>

<p>Let’s fix some notation.</p>

<ul>
  <li><script type="math/tex">W_h\in \mathbb{R}^{\text{hidden_size }\times 2}</script> = weights of each of the neurons in the hidden layer.</li>
  <li><script type="math/tex">b_h\in \mathbb{R}^{\text{hidden_size}}</script> = bias term in hidden units.</li>
  <li><script type="math/tex">W_o\in \mathbb{R}^{\text{hidden_size}}</script> = weights on the outcome unit.</li>
  <li><script type="math/tex">b_o \in \mathbb{R}</script> = bias term in output unit.</li>
</ul>

<p>Then we have the following equations, that we use for <strong>forward propagation</strong>,</p>

<ul>
  <li><script type="math/tex">a_h= W_h\cdot x + b_h</script>.</li>
  <li><script type="math/tex">y_h=f(a_h)</script>.</li>
  <li><script type="math/tex">a_o=W_o\cdot y_h+b_0</script>.</li>
  <li><script type="math/tex">y_o=f(a_o)</script>.</li>
</ul>

<p>Where <script type="math/tex">f</script> is the activation function, <script type="math/tex">x\in \mathbb{R}^2</script> is the input data, and <script type="math/tex">y_o\in \mathbb{R}</script> is the output of the model.</p>

<h2 id="backpropagation">Backpropagation.</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Hyperbolic Tangent function</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><script type="math/tex">\delta_o=(\hat{y}-y_o)(1-y_o^2)</script></td>
    </tr>
    <tr>
      <td style="text-align: center"><script type="math/tex">\delta_h=(1-y^2_h)</script></td>
    </tr>
    <tr>
      <td style="text-align: center"><script type="math/tex">\frac{\partial E}{\partial W_0}=\delta_o y_h</script></td>
    </tr>
    <tr>
      <td style="text-align: center"><script type="math/tex">\frac{\partial E}{\partial b_0}=\delta_o</script></td>
    </tr>
    <tr>
      <td style="text-align: center"><script type="math/tex">\frac{\partial E}{\partial W_h}=\delta_o W_o\delta_hx</script></td>
    </tr>
    <tr>
      <td style="text-align: center"><script type="math/tex">\frac{\partial E}{\partial b_h}=\delta_oW_o\delta_h</script></td>
    </tr>
  </tbody>
</table>

<p><strong>IMPORTANT:</strong> The vectors and matrix multiplication described on the table are component wise, in particular they are not given by dot product.</p>

<h2 id="implementation">Implementation</h2>

<p>We are ready for the implementation:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># The activation functions:</span>

<span class="n">from</span> <span class="n">numpy</span> <span class="n">import</span> <span class="n">tanh</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="c1">#Our conventions</span>
<span class="n">dim_input</span><span class="o">=</span><span class="mi">2</span>
<span class="n">dim_output</span><span class="o">=</span><span class="mi">1</span>


<span class="k">def</span> <span class="nf">ourFirstNN</span><span class="p">(</span><span class="no">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">num_passes</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">01</span><span class="p">):</span>
    
    <span class="c1">#Let's get some info</span>
    <span class="n">data_size</span><span class="o">=</span><span class="n">len</span><span class="p">(</span><span class="no">X</span><span class="p">)</span>
    
    
    
    <span class="c1"># Initialize the parameters to random values. </span>
    
    <span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>
    
    
    
    <span class="no">W_h</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">dim_input</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">dim_input</span><span class="p">)</span>
    <span class="n">b_h</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
    <span class="no">W_o</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="n">b_o</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="c1">#Let's keep track of sizes: </span>
    <span class="c1">#x is (2,)</span>
    <span class="c1">#W_h is (2,n)</span>
    <span class="c1">#b_h is (1,n)</span>
    <span class="c1">#W_o is (n,1)</span>
    <span class="c1">#b_0 is (1,1)</span>
    
    <span class="k">if</span> <span class="n">activation</span><span class="o">==</span><span class="s1">'tanh'</span><span class="p">:</span>
        
        <span class="c1">#Converting our outcome y to {-1,1}</span>
        <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="n">num_passes</span><span class="p">):</span>
            
            <span class="c1">#pick a random training data element</span>
            <span class="n">randInt</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">len</span><span class="p">(</span><span class="no">X</span><span class="p">))</span>
            <span class="n">x</span><span class="o">=</span><span class="no">X</span><span class="p">[</span><span class="n">randInt</span><span class="p">]</span>
            <span class="n">y_hat</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">randInt</span><span class="p">]</span>
            
            
            <span class="c1">#Forward propagation</span>
            <span class="n">a_h</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="no">W_h</span><span class="p">)</span><span class="o">+</span><span class="n">b_h</span>
            <span class="n">y_h</span><span class="o">=</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_h</span><span class="p">)</span>
            <span class="n">a_o</span><span class="o">=</span><span class="n">y_h</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="no">W_o</span><span class="p">)</span><span class="o">+</span><span class="n">b_o</span>
            <span class="n">y_o</span><span class="o">=</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_o</span><span class="p">)</span>
            
            <span class="c1">#Let's keep track of sizes: </span>
            <span class="c1">#a_h is (1,2)\cdot(2,n)+(1,n)=(200,n) (By broadcasting)</span>
            <span class="c1">#y_h is (1,n)</span>
            <span class="c1">#a_o is (1,n)\cdot(n,1)+(1,1)=(200,1) (By broadcasting)</span>
            <span class="c1">#y_o is (1,1)</span>
            
            
            <span class="c1">#BackPropagation</span>
            <span class="n">delta_o</span><span class="o">=</span><span class="p">(</span><span class="n">y_o</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_o</span><span class="o">*</span><span class="n">y_o</span><span class="p">)</span>
            <span class="n">delta_h</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_h</span><span class="o">*</span><span class="n">y_h</span><span class="p">)</span>
            <span class="n">dEdW_o</span><span class="o">=</span><span class="n">delta_o</span><span class="o">*</span><span class="n">y_h</span>
            <span class="n">dEdb_o</span><span class="o">=</span><span class="n">delta_o</span>
            <span class="n">dEdW_h</span><span class="o">=</span><span class="p">(((</span><span class="n">delta_o</span><span class="o">.</span><span class="no">T</span><span class="o">*</span><span class="no">W_o</span><span class="p">)</span><span class="o">*</span><span class="n">delta_h</span><span class="o">.</span><span class="no">T</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="no">T</span><span class="p">))</span><span class="o">.</span><span class="no">T</span> 
            <span class="n">dEdb_h</span><span class="o">=</span><span class="p">(((</span><span class="n">delta_o</span><span class="o">.</span><span class="no">T</span><span class="o">*</span><span class="no">W_o</span><span class="p">)</span><span class="o">*</span><span class="n">delta_h</span><span class="o">.</span><span class="no">T</span><span class="p">))</span><span class="o">.</span><span class="no">T</span> 

            
            <span class="c1">#Let's keep track of sizes: </span>
            <span class="c1">#delta_o is (1,1)</span>
            <span class="c1">#delta_h is (1,n)</span>
            <span class="c1">#dEdW_o is (1,1)(1,n)=(1,n)</span>
            <span class="c1">#dEdb_o is (1,1)</span>
            <span class="c1">#dEdW_h is (2,n)</span>
            <span class="c1">#dEdb_h is (1,n)</span>

            <span class="c1">#Updating the values</span>
            <span class="c1"># Gradient descent parameter update</span>
            <span class="no">W_o</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">dEdW_o</span><span class="o">.</span><span class="no">T</span><span class="p">)</span>
            <span class="n">b_o</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dEdb_o</span>
            <span class="no">W_h</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dEdW_h</span>
            <span class="n">b_h</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dEdb_h</span>
            
        
        <span class="c1">#giving the model</span>
        <span class="k">return</span> <span class="p">{</span> <span class="s1">'W_o'</span><span class="p">:</span> <span class="no">W_o</span><span class="p">,</span> <span class="s1">'b_o'</span><span class="p">:</span> <span class="n">b_o</span><span class="p">,</span> <span class="s1">'W_h'</span><span class="p">:</span> <span class="no">W_h</span><span class="p">,</span> <span class="s1">'b_h'</span><span class="p">:</span> <span class="n">b_h</span><span class="p">}</span>
        
    <span class="n">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">'sigmoid'</span><span class="p">:</span>
        
        <span class="c1">#You should do this as an exercise, just follow the same steps that we did for hyperbolic tangent.</span>
        <span class="n">pass</span>
    
        
    </code></pre></figure>

<p>In order to test our model, we need to evalue it, we can use the forward propagation piece of code for this.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="no">W_o</span><span class="p">,</span><span class="n">b_o</span><span class="p">,</span><span class="no">W_h</span><span class="p">,</span><span class="n">b_h</span><span class="p">):</span>
    
    <span class="n">a_h</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="no">W_h</span><span class="p">)</span><span class="o">+</span><span class="n">b_h</span>
    <span class="n">y_h</span><span class="o">=</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_h</span><span class="p">)</span>
    <span class="n">a_o</span><span class="o">=</span><span class="n">y_h</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="no">W_o</span><span class="p">)</span><span class="o">+</span><span class="n">b_o</span>
    <span class="n">y_o</span><span class="o">=</span><span class="n">tanh</span><span class="p">(</span><span class="n">a_o</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y_o</span></code></pre></figure>

<p>We are amost ready to see how we did. We borrow the plot function from <a href="https://github.com/dennybritz/nn-from-scratch/blob/master/nn-from-scratch.ipynb">Denny Britz</a>.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span><span class="n">pred_func</span><span class="p">):</span>
    <span class="c1"># Set min and max values and give it some padding</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="no">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="no">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="no">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="no">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mo">01</span>
    <span class="c1"># Generate a grid of points with distance h between them</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="c1"># Predict the function value for the whole gid</span>
    <span class="no">Z</span> <span class="o">=</span> <span class="n">pred_func</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">c_</span><span class="p">[</span><span class="n">xx</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()])</span>
    <span class="no">Z</span> <span class="o">=</span> <span class="no">Z</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">xx</span><span class="p">.</span><span class="nf">shape</span><span class="p">)</span>
    <span class="c1"># Plot the contour and training examples</span>
    <span class="n">frame1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">()</span>
    <span class="n">frame1</span><span class="p">.</span><span class="nf">axes</span><span class="p">.</span><span class="nf">get_xaxis</span><span class="p">().</span><span class="nf">set_visible</span><span class="p">(</span><span class="no">False</span><span class="p">)</span>
    <span class="n">frame1</span><span class="p">.</span><span class="nf">axes</span><span class="p">.</span><span class="nf">get_yaxis</span><span class="p">().</span><span class="nf">set_visible</span><span class="p">(</span><span class="no">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="no">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">cm</span><span class="p">.</span><span class="nf">cool</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="no">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="no">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">cm</span><span class="p">.</span><span class="nf">cool</span><span class="p">)</span></code></pre></figure>

<p>Next we look at some interesting models, and see what happens when we change the different parameters of our training.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">))</span>
        <span class="n">model</span><span class="o">=</span><span class="n">ourFirstNN</span><span class="p">(</span><span class="no">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">num_passes</span><span class="o">=</span><span class="mi">5000</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">01</span><span class="p">)</span>
        <span class="no">W_o</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'W_o'</span><span class="p">]</span>
        <span class="n">b_o</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'b_o'</span><span class="p">]</span>
        <span class="no">W_h</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'W_h'</span><span class="p">]</span>
        <span class="n">b_h</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'b_h'</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">pred_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="no">W_o</span><span class="p">,</span><span class="n">b_o</span><span class="p">,</span><span class="no">W_h</span><span class="p">,</span><span class="n">b_h</span><span class="p">)</span>

        <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">pred_func</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">str</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">5000</span><span class="p">)</span><span class="o">+</span><span class="s2">" data points </span><span class="se">\n</span><span class="s2"> "</span><span class="o">+</span><span class="n">str</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="s2">" neurons."</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/Our_first_NN_files/Our_first_NN_24_0.png" alt="" /></p>

<p>Where the beautiful graphs, are giving just how close a point is from being -1 (yellow) or 1 (blue). If we want to find the regions, we will get the following.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplot2grid</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">))</span>
        <span class="n">model</span><span class="o">=</span><span class="n">ourFirstNN</span><span class="p">(</span><span class="no">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">num_passes</span><span class="o">=</span><span class="mi">5000</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">01</span><span class="p">)</span>
        <span class="no">W_o</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'W_o'</span><span class="p">]</span>
        <span class="n">b_o</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'b_o'</span><span class="p">]</span>
        <span class="no">W_h</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'W_h'</span><span class="p">]</span>
        <span class="n">b_h</span><span class="o">=</span><span class="n">model</span><span class="p">[</span><span class="s1">'b_h'</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">pred_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="no">W_o</span><span class="p">,</span><span class="n">b_o</span><span class="p">,</span><span class="no">W_h</span><span class="p">,</span><span class="n">b_h</span><span class="p">)</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">pred_func</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">str</span><span class="p">((</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">5000</span><span class="p">)</span><span class="o">+</span><span class="s2">" data points </span><span class="se">\n</span><span class="s2"> "</span><span class="o">+</span><span class="n">str</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="s2">" neurons."</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/Our_first_NN_files/Our_first_NN_26_0.png" alt="" /></p>

<p>Isn’t this amazing?</p>


  <!-- POST NAVIGATION -->
  <div class="postNav clearfix">
     
      <a class="prev" href="/blog/neural-nets/"><span>&laquo;&nbsp;Neural Networks</span>
      
    </a>
      
      
      <a class="next" href="/blog/K-armed/"><span>The K-armed Bandit&nbsp;&raquo;</span>
       
      </a>
     
  </div>
</div>

      	</div>
      	
      	


	</div><!-- end .content -->


   <div class="footer">
   <div class="container">
      <p class="copy">&copy; 2016 <a href="https://scy1505.github.io">Felipe Pérez.</a> Powered by <a href="http://jekyllrb.com">Jekyll</a></p>

      <div class="footer-links"> 
         <ul class="noList"> 
            
            <li><a href="https://www.facebook.com/juan1505">
                  <svg id="facebook-square" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M82.667,1H17.335C8.351,1,1,8.351,1,17.336v65.329c0,8.99,7.351,16.335,16.334,16.335h65.332 C91.652,99.001,99,91.655,99,82.665V17.337C99,8.353,91.652,1.001,82.667,1L82.667,1z M84.318,50H68.375v42.875H50V50h-8.855V35.973 H50v-9.11c0-12.378,5.339-19.739,19.894-19.739h16.772V22.3H72.967c-4.066-0.007-4.57,2.12-4.57,6.078l-0.023,7.594H86.75 l-2.431,14.027V50z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://twitter.com/jperezvallejo">
                  <svg id="twitter" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M99.001,19.428c-3.606,1.608-7.48,2.695-11.547,3.184c4.15-2.503,7.338-6.466,8.841-11.189 c-3.885,2.318-8.187,4-12.768,4.908c-3.667-3.931-8.893-6.387-14.676-6.387c-11.104,0-20.107,9.054-20.107,20.223 c0,1.585,0.177,3.128,0.52,4.609c-16.71-0.845-31.525-8.895-41.442-21.131C6.092,16.633,5.1,20.107,5.1,23.813 c0,7.017,3.55,13.208,8.945,16.834c-3.296-0.104-6.397-1.014-9.106-2.529c-0.002,0.085-0.002,0.17-0.002,0.255 c0,9.799,6.931,17.972,16.129,19.831c-1.688,0.463-3.463,0.71-5.297,0.71c-1.296,0-2.555-0.127-3.783-0.363 c2.559,8.034,9.984,13.882,18.782,14.045c-6.881,5.424-15.551,8.657-24.971,8.657c-1.623,0-3.223-0.096-4.796-0.282 c8.898,5.738,19.467,9.087,30.82,9.087c36.982,0,57.206-30.817,57.206-57.543c0-0.877-0.02-1.748-0.059-2.617 C92.896,27.045,96.305,23.482,99.001,19.428z"></path>
                  </svg>
            </a></li>
            
            
            <li><a href="https://github.com/scy1505">
                  <svg id="github" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M79.099,79.099 c-3.782,3.782-8.184,6.75-13.083,8.823c-1.245,0.526-2.509,0.989-3.79,1.387v-7.344c0-3.86-1.324-6.699-3.972-8.517 c1.659-0.16,3.182-0.383,4.57-0.67c1.388-0.287,2.855-0.702,4.402-1.245c1.547-0.543,2.935-1.189,4.163-1.938 c1.228-0.75,2.409-1.723,3.541-2.919s2.082-2.552,2.847-4.067s1.372-3.334,1.818-5.455c0.446-2.121,0.67-4.458,0.67-7.01 c0-4.945-1.611-9.155-4.833-12.633c1.467-3.828,1.308-7.991-0.478-12.489l-1.197-0.143c-0.829-0.096-2.321,0.255-4.474,1.053 c-2.153,0.798-4.57,2.105-7.249,3.924c-3.797-1.053-7.736-1.579-11.82-1.579c-4.115,0-8.039,0.526-11.772,1.579 c-1.69-1.149-3.294-2.097-4.809-2.847c-1.515-0.75-2.727-1.26-3.637-1.532c-0.909-0.271-1.754-0.439-2.536-0.503 c-0.782-0.064-1.284-0.079-1.507-0.048c-0.223,0.031-0.383,0.064-0.478,0.096c-1.787,4.53-1.946,8.694-0.478,12.489 c-3.222,3.477-4.833,7.688-4.833,12.633c0,2.552,0.223,4.889,0.67,7.01c0.447,2.121,1.053,3.94,1.818,5.455 c0.765,1.515,1.715,2.871,2.847,4.067s2.313,2.169,3.541,2.919c1.228,0.751,2.616,1.396,4.163,1.938 c1.547,0.543,3.014,0.957,4.402,1.245c1.388,0.287,2.911,0.511,4.57,0.67c-2.616,1.787-3.924,4.626-3.924,8.517v7.487 c-1.445-0.43-2.869-0.938-4.268-1.53c-4.899-2.073-9.301-5.041-13.083-8.823c-3.782-3.782-6.75-8.184-8.823-13.083 C9.934,60.948,8.847,55.56,8.847,50s1.087-10.948,3.231-16.016c2.073-4.899,5.041-9.301,8.823-13.083s8.184-6.75,13.083-8.823 C39.052,9.934,44.44,8.847,50,8.847s10.948,1.087,16.016,3.231c4.9,2.073,9.301,5.041,13.083,8.823 c3.782,3.782,6.75,8.184,8.823,13.083c2.143,5.069,3.23,10.457,3.23,16.016s-1.087,10.948-3.231,16.016 C85.848,70.915,82.88,75.317,79.099,79.099L79.099,79.099z"></path>
                  </svg>
            </a></li>
             
            
            <li><a href="mailto:juan1505@gmail.com">
                  <svg id="mail" class="custom-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 100 100" style="height: 30px; width: 30px;"><circle class="outer-shape" cx="50" cy="50" r="48" style="opacity: 1;"></circle>
                  <path class="inner-shape" style="opacity: 1;" transform="translate(25,25) scale(0.5)" d="M50,1C22.938,1,1,22.938,1,50s21.938,49,49,49s49-21.938,49-49S77.062,1,50,1z M25.5,25.5h49 c0.874,0,1.723,0.188,2.502,0.542L50,57.544L22.998,26.041C23.777,25.687,24.626,25.499,25.5,25.5L25.5,25.5z M19.375,68.375v-36.75 c0-0.128,0.005-0.256,0.014-0.383l17.96,20.953L19.587,69.958C19.448,69.447,19.376,68.916,19.375,68.375L19.375,68.375z M74.5,74.5 h-49c-0.541,0-1.072-0.073-1.583-0.212l17.429-17.429L50,66.956l8.653-10.096l17.429,17.429C75.572,74.427,75.041,74.5,74.5,74.5 L74.5,74.5z M80.625,68.375c0,0.541-0.073,1.072-0.211,1.583L62.652,52.195l17.96-20.953c0.008,0.127,0.014,0.255,0.014,0.383 L80.625,68.375L80.625,68.375z"></path>
                  </svg>
            </a></li>
            
         </ul>
      </div>
   </div>
</div><!-- end .footer -->


  
   <!-- Add jQuery and other scripts -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src=""><\/script>')</script>
<script src="/assets/js/dropcap.min.js"></script>
<script src="/assets/js/responsive-nav.min.js"></script>
<script src="/assets/js/scripts.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



</body>

</html>
